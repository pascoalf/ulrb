[{"path":"https://pascoalf.github.io/ulrb/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://pascoalf.github.io/ulrb/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://pascoalf.github.io/ulrb/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://pascoalf.github.io/ulrb/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://pascoalf.github.io/ulrb/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://pascoalf.github.io/ulrb/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://pascoalf.github.io/ulrb/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://pascoalf.github.io/ulrb/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://pascoalf.github.io/ulrb/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://pascoalf.github.io/ulrb/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://pascoalf.github.io/ulrb/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://pascoalf.github.io/ulrb/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://pascoalf.github.io/ulrb/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://pascoalf.github.io/ulrb/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://pascoalf.github.io/ulrb/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://pascoalf.github.io/ulrb/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://pascoalf.github.io/ulrb/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://pascoalf.github.io/ulrb/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://pascoalf.github.io/ulrb/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://pascoalf.github.io/ulrb/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://pascoalf.github.io/ulrb/articles/Glossary.html","id":"why-we-made-this-tutorial","dir":"Articles","previous_headings":"","what":"Why we made this tutorial","title":"Glossary","text":"tutorial aims clarify nomenclature used urlb package. methodological issues specific microbial ecology taxonomy; might confusing non-microbiologists. hand, terms data science machine learning may obvious microbiologists. finally, course, nomenclature understandable researchers focus non-microbiome datasets.","code":""},{"path":"https://pascoalf.github.io/ulrb/articles/Glossary.html","id":"phylogenetic-units","dir":"Articles","previous_headings":"","what":"Phylogenetic units","title":"Glossary","text":"decided use term “phylogenetic units” instead “species”. Species simplest term, problematic term microbial ecology. Briefly, microbial ecology requires usage high-throughput sequencing based methods distinguish microorganisms environment; usually hard describe species level. Thus, usually refer “species” instead refer proxy species. proxy can , example, “amplicon sequence variants” (ASV), “operational taxonomic units” (OTU) . However, terms specific methods used specific situations. try generalize, compromised “phylogenetic units”, represent idea independently method used (avoid problem species definition). Another possibility “taxa/taxon”, simple. However, cause confusion, different taxonomic levels. , phylogenetic units might taxonomy less resolved, purposes package care specific taxonomies, care distinguishes different entities, thus, phylogenetic units.","code":""},{"path":"https://pascoalf.github.io/ulrb/articles/Glossary.html","id":"phylogenetic-units-translated-to-machine-learning","dir":"Articles","previous_headings":"","what":"Phylogenetic units translated to machine learning","title":"Glossary","text":"terms machine learning algorithms (just ones used ), phylogenetic units represent observations (objects). Thus, row represent phylogenetic unit, column providing ID phylogenetic unit.","code":""},{"path":"https://pascoalf.github.io/ulrb/articles/Glossary.html","id":"variables-and-features","dir":"Articles","previous_headings":"","what":"Variables and features","title":"Glossary","text":"phylogenetic unit might several variables, features, single feature considered ulrb abundance score. abundance score different methodology, study design, etc. However, always sort abundance table sort abundance score. purposes ulrb matter score obtained. Extra variables allowed, ignored purpose actual algorithm. Except sample variable, used grouping phylogenetic units. Basically, algorithm applied sample provided independently. sample confused observation context. Think sample physical representative community phylogenetic units; phylogenetic unit “observe” present (given abundance score) said sample. Additionally, samples provide extra variables, might include environmental metadata. However, additional data ignored ulrb package. Thus, can abundance table long format includes available metadata (can include environmental, methodological, taxa… details) ulrb just add new columns new variables – like abundance classification details clustering result.","code":""},{"path":"https://pascoalf.github.io/ulrb/articles/Glossary.html","id":"abundance-classification","dir":"Articles","previous_headings":"","what":"Abundance classification","title":"Glossary","text":"word “classification” can ambiguous, might refer “taxonomic” classification, “abundance” classification. ulrb, dealing classification problem, know classify phylogenetic units based abundance score. use classification ulrb, result clustering, can assert abundance classification lowest abundance phylogenetic units represents rare biosphere, . Thus, refer “abundance classification” referring actual result ulrb, function define_rb().","code":""},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/articles/eco-analysis.html","id":"ecological-analysis-of-microbial-rare-biosphere-defined-by-ulrb","dir":"Articles","previous_headings":"","what":"Ecological analysis of microbial rare biosphere defined by ulrb","title":"Integration of ulrb in a simple microbial ecology workflow","text":"tutorial show output define_rb() can readily used common ecological analysis. case, just look alpha diversity. , several steps: Load clean OTU table (just want prokaryotes); Rarefy samples (show option, common); Classify OTUs rare, undetermined abundant (define_rb() function); Merge OTU table metadata information; Calculate plot alpha diversity metrics environmental variables.","code":""},{"path":"https://pascoalf.github.io/ulrb/articles/eco-analysis.html","id":"quick-overview-of-n-ice-dataset","dir":"Articles","previous_headings":"Ecological analysis of microbial rare biosphere defined by ulrb","what":"Quick overview of N-ICE dataset","title":"Integration of ulrb in a simple microbial ecology workflow","text":"N-ICE dataset consists 9 samples, collected winter spring transition 2015 fixing vessel drifting ice (Granskog et al., 2018). Samples collected various depths (5m 250m) ice drifted across different regions, DNA collected 16S amplicon sequencing metagenomes (de Sousa et al., 2019); bioinformatic processing reads performed Mgnify platform (v5) (Mitchel et al., 2020). tutorial using OTU table downloaded link https://www.ebi.ac.uk/metagenomics/studies/MGYS00001922#analysis 06-01-2023 focus solely 16S amplicon data.","code":"library(ulrb) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(tidyr) library(vegan) #> Loading required package: permute #> Loading required package: lattice #> This is vegan 2.6-8 library(ggplot2) library(purrr) # set.seed(123)"},{"path":"https://pascoalf.github.io/ulrb/articles/eco-analysis.html","id":"a-load-and-clean-otu-table","dir":"Articles","previous_headings":"Ecological analysis of microbial rare biosphere defined by ulrb","what":"(a) Load and clean OTU table","title":"Integration of ulrb in a simple microbial ecology workflow","text":"","code":"# Load raw OTU table from N-ICE data(\"nice_raw\", package = \"ulrb\") data(\"nice_env\", package = \"ulrb\")  # Change name of first column nice_clean <- rename(nice_raw, Taxonomy = \"X.SampleID\")  # Select 16S rRNA amplicon sequencing samples selected_samples <- c(\"ERR2044662\", \"ERR2044663\", \"ERR2044664\",                       \"ERR2044665\", \"ERR2044666\", \"ERR2044667\",                       \"ERR2044668\", \"ERR2044669\", \"ERR2044670\")  # Add a column with phylogenetic units ID (OTU in this case) nice_clean <- mutate(nice_clean, OTU = paste0(\"OTU_\", row_number()))  # Select relevant collumns nice_clean <- select(nice_clean, selected_samples, OTU, Taxonomy) #> Warning: Using an external vector in selections was deprecated in tidyselect 1.1.0. #> ℹ Please use `all_of()` or `any_of()` instead. #>   # Was: #>   data %>% select(selected_samples) #>  #>   # Now: #>   data %>% select(all_of(selected_samples)) #>  #> See <https://tidyselect.r-lib.org/reference/faq-external-vector.html>. #> This warning is displayed once every 8 hours. #> Call `lifecycle::last_lifecycle_warnings()` to see where this warning was #> generated.  # Separate Taxonomy column into each taxonomic level nice_clean <- separate(nice_clean, Taxonomy,                        c(\"Domain\",\"Kingdom\",\"Phylum\",                          \"Class\",\"Order\",\"Family\",\"Genus\",\"Species\"),                        sep=\";\") #> Warning: Expected 8 pieces. Missing pieces filled with `NA` in 912 rows [1, 2, 4, 5, 6, #> 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, ...].  # Remove Kingdom column, because it is not used for prokaryotes nice_clean <- select(nice_clean, -Kingdom)  # Remove eukaryotes nice_clean <- filter(nice_clean, Domain != \"sk__Eukaryota\")  # Remove unclassified OTUs at phylum level nice_clean <- filter(nice_clean, !is.na(Phylum))  # Simplify name nice <- nice_clean  # Check if everything looks normal head(nice) #>   ERR2044662 ERR2044663 ERR2044664 ERR2044665 ERR2044666 ERR2044667 ERR2044668 #> 1        165        323         51         70        134        216          0 #> 2          0          0          1          0          0          1          0 #> 3          0          0          1          2          2          6          0 #> 4        541       1018        351        115        241       1633        177 #> 5          8          5         41         15         14        146          0 #> 6         15         31        590        133        174       1814         12 #>   ERR2044669 ERR2044670   OTU      Domain            Phylum #> 1         11          0 OTU_2 sk__Archaea  p__Euryarchaeota #> 2          0          0 OTU_3 sk__Archaea  p__Euryarchaeota #> 3          0          0 OTU_4 sk__Archaea  p__Euryarchaeota #> 4       1371          7 OTU_5 sk__Archaea  p__Euryarchaeota #> 5         14          0 OTU_6 sk__Archaea p__Thaumarchaeota #> 6        173          2 OTU_7 sk__Archaea p__Thaumarchaeota #>                       Class                       Order Family #> 1 c__Candidatus_Poseidoniia                        <NA>   <NA> #> 2 c__Candidatus_Poseidoniia o__Candidatus_Poseidoniales    f__ #> 3           c__Halobacteria          o__Halobacteriales   <NA> #> 4         c__Thermoplasmata                        <NA>   <NA> #> 5                      <NA>                        <NA>   <NA> #> 6                       c__                         o__    f__ #>                            Genus                                        Species #> 1                           <NA>                                           <NA> #> 2                            g__ s__Marine_group_II_euryarchaeote_REDSEA-S03_B6 #> 3                           <NA>                                           <NA> #> 4                           <NA>                                           <NA> #> 5                           <NA>                                           <NA> #> 6 g__Candidatus_Nitrosopelagicus                                           <NA>  # Change table to tidy format # You can automatically do this with an ulrb function nice_tidy <- prepare_tidy_data(nice, ## data to tidy                    sample_names = contains(\"ERR\"), ## vector with ID samples                   samples_in = \"cols\") ## samples can be in columns (cols) or rows."},{"path":"https://pascoalf.github.io/ulrb/articles/eco-analysis.html","id":"b-rarefy-samples","dir":"Articles","previous_headings":"Ecological analysis of microbial rare biosphere defined by ulrb","what":"(b) Rarefy samples","title":"Integration of ulrb in a simple microbial ecology workflow","text":"Now tidy table, important keep mind data organized. tutorial, using functions like group_by() nest(), familiarized , try search tidyverse packages, functions mindset. also going use package vegan, can used ecology statistics. Note, however, vegan works matrices specific formats, hopefully sections also help see can use tidy verse approaches specific data types. first step verify many reads sample got  samples 50 000 reads, one sample little bit less. think can keep samples rarefy 40 000 reads.","code":"## First, check how many reads each sample got nice_tidy %>%    group_by(Sample) %>% ## because data is in tidy format   summarise(TotalReads = sum(Abundance)) %>%    ggplot(aes(Sample, TotalReads)) +    geom_hline(yintercept = 40000) +    geom_col() +    theme_bw() +    coord_flip() nice_rarefid <-    nice_tidy %>%    group_by(Sample) %>%   nest() %>%    mutate(Rarefied_reads = map(.x = data,                                ~as.data.frame(                                 t(                                   rrarefy(                                     .x$Abundance,                                      sample = 40000))))) %>%    unnest(c(data,Rarefied_reads))%>%    rename(Rarefied_abundance = \"V1\")"},{"path":"https://pascoalf.github.io/ulrb/articles/eco-analysis.html","id":"b-classify-otus-into-rare-undetermined-or-abundant-with-define_rb-function","dir":"Articles","previous_headings":"Ecological analysis of microbial rare biosphere defined by ulrb","what":"(b) Classify OTUs into rare, undetermined or abundant (with define_rb() function);","title":"Integration of ulrb in a simple microbial ecology workflow","text":"stage, can simply apply define_rb() function, include nesting grouping step inside . reason, data need grouped function. unit testing, however, noticed introduce problems, function implicitly removes grouping tidy table used author. way, pre-specific grouping function used. control , just need careful sample column, ulrb method assumes calculations made “sample” – , ungroup() followed group_by(Sample). practice, simple: default, function can give lots details, case, since just going look ecology component, machine learning aspects , can set argument simplified TRUE. Note additional computational time required additional details negligible small datasets (don’t know behaves bigger datasets).","code":"nice_classified <- define_rb(nice_tidy, simplified = TRUE) #> Joining with `by = join_by(Sample, Level)` head(nice_classified) #> # A tibble: 6 × 17 #> # Groups:   Sample, Classification [1] #>   Sample     Classification OTU   Domain Phylum Class Order Family Genus Species #>   <chr>      <fct>          <chr> <chr>  <chr>  <chr> <chr> <chr>  <chr> <chr>   #> 1 ERR2044662 Rare           OTU_2 sk__A… p__Eu… c__C… NA    NA     NA    NA      #> 2 ERR2044662 Rare           OTU_5 sk__A… p__Eu… c__T… NA    NA     NA    NA      #> 3 ERR2044662 Rare           OTU_6 sk__A… p__Th… NA    NA    NA     NA    NA      #> 4 ERR2044662 Rare           OTU_7 sk__A… p__Th… c__   o__   f__    g__C… NA      #> 5 ERR2044662 Rare           OTU_8 sk__A… p__Th… c__   o__N… NA     NA    NA      #> 6 ERR2044662 Rare           OTU_… sk__A… p__Th… c__   o__N… f__Ni… g__N… NA      #> # ℹ 7 more variables: Abundance <int>, pam_object <list>, Level <fct>, #> #   Silhouette_scores <dbl>, Cluster_median_abundance <dbl>, #> #   median_Silhouette <dbl>, Evaluation <chr>"},{"path":"https://pascoalf.github.io/ulrb/articles/eco-analysis.html","id":"c-merge-otu-table-with-metadata-information","dir":"Articles","previous_headings":"Ecological analysis of microbial rare biosphere defined by ulrb","what":"(c) Merge OTU table with metadata information","title":"Integration of ulrb in a simple microbial ecology workflow","text":"almost ready analyze ecological questions, first need metadata. merge classified OTU table metadata table. use join functions dplyr, just note sample ID two tables want merge different, easy solve.","code":"nice_eco <- nice_classified %>% left_join(nice_env, by = c(\"Sample\" = \"ENA_ID\"))"},{"path":"https://pascoalf.github.io/ulrb/articles/eco-analysis.html","id":"e-calculate-and-plot-diversity-metrics-against-environmental-variables-","dir":"Articles","previous_headings":"Ecological analysis of microbial rare biosphere defined by ulrb","what":"(e) Calculate and plot diversity metrics against environmental variables.","title":"Integration of ulrb in a simple microbial ecology workflow","text":"point, can calculate common alpha diversity metrics. use dplyr ggplot functions, becomes really easy make simple overview prokaryotic diversity, classification.","code":"# Calculate diversity nice_diversity <- nice_eco %>%    group_by(Sample, Classification, Month, Depth, Water.mass) %>%    summarise(SpeciesRichness = specnumber(Abundance),             ShannonIndex = diversity(Abundance, index = \"shannon\"),             SimpsonIndex = diversity(Abundance, index = \"simpson\")) %>%    ungroup() #> `summarise()` has grouped output by 'Sample', 'Classification', 'Month', #> 'Depth'. You can override using the `.groups` argument. ## Re-organize table to have all diversity indices in a single col. nice_diversity_tidy <- nice_diversity %>%    pivot_longer(cols = c(\"SpeciesRichness\", \"ShannonIndex\", \"SimpsonIndex\"),                names_to = \"Index\",                values_to = \"Diversity\") %>%  # correct order   mutate(Month = factor(Month, levels = c(\"March\", \"April\", \"June\"))) %>%  # edit diversity index names   mutate(Index = case_when(Index == \"ShannonIndex\" ~ \"Shannon Index\",                            Index == \"SimpsonIndex\" ~ \"Simpson Index\",                            TRUE ~ \"Number of OTUs\")) %>%   # order diversity index names   mutate(Index = factor(Index, c(\"Number of OTUs\", \"Shannon Index\",\"Simpson Index\")))"},{"path":"https://pascoalf.github.io/ulrb/articles/eco-analysis.html","id":"alpha-diversity-plots","dir":"Articles","previous_headings":"Ecological analysis of microbial rare biosphere defined by ulrb > (e) Calculate and plot diversity metrics against environmental variables.","what":"Alpha diversity plots","title":"Integration of ulrb in a simple microbial ecology workflow","text":"stage, everything single tidy data.frame, makes ggplot plots straightforward. Month variation  Water mass variation","code":"qualitative_colors <-    c(\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")  ## Plots nice_diversity_tidy %>%   ggplot(aes(Month, Diversity, col = Classification)) +    geom_point() +    facet_wrap(~Index, scales = \"free_y\")+   scale_color_manual(values = qualitative_colors[c(5,3,6)]) +    theme_bw() +    theme(strip.background = element_blank(),         strip.text = element_text(size = 12),         legend.position = \"top\") +    labs(col = \"Classification: \",        title = \"Alpha diversity across month\") nice_diversity_tidy %>%    ggplot(aes(Water.mass, Diversity, col = Classification)) +    geom_point() +    facet_wrap(~Index, scales = \"free_y\")+   scale_color_manual(values = qualitative_colors[c(5,3,6)]) +    theme_bw() +    theme(strip.background = element_blank(),         strip.text = element_text(size = 12),         legend.position = \"top\") %>%   labs(col = \"Classification: \",        title = \"Alpha diversity across water mass\")"},{"path":"https://pascoalf.github.io/ulrb/articles/eco-analysis.html","id":"beta-diversity","dir":"Articles","previous_headings":"Ecological analysis of microbial rare biosphere defined by ulrb > (e) Calculate and plot diversity metrics against environmental variables.","what":"Beta diversity","title":"Integration of ulrb in a simple microbial ecology workflow","text":"can also basic beta diversity. Note might require little bit data wrangling. section, focus rare biosphere. Months  analysis, seems community composition rare biosphere different June remaining months.","code":"rare_biosphere <-    nice_eco %>%     filter(Classification == \"Rare\") %>%    select(Sample, Abundance, OTU, Depth, Month, Water.mass) %>%    mutate(Sample_unique = paste(Sample, Month)) #> Adding missing grouping variables: `Classification`  rb_env <- rare_biosphere %>%    ungroup() %>%    select(Sample_unique, Depth, Water.mass, Month) %>%    distinct()  rb_sp_prep <- rare_biosphere %>%    ungroup() %>%    select(Sample_unique, Abundance, OTU)  rb_sp_prep %>% head() # sanity check #> # A tibble: 6 × 3 #>   Sample_unique    Abundance OTU    #>   <chr>                <int> <chr>  #> 1 ERR2044662 March       165 OTU_2  #> 2 ERR2044662 March       541 OTU_5  #> 3 ERR2044662 March         8 OTU_6  #> 4 ERR2044662 March        15 OTU_7  #> 5 ERR2044662 March         5 OTU_8  #> 6 ERR2044662 March         4 OTU_10  rb_sp <-    rb_sp_prep %>%    tidyr::pivot_wider(names_from = \"OTU\",                      values_from = \"Abundance\",                      values_fn = list(count= list)) %>%    print() %>%    unchop(everything()) #> # A tibble: 9 × 523 #>   Sample_unique OTU_2 OTU_5 OTU_6 OTU_7 OTU_8 OTU_10 OTU_15 OTU_17 OTU_21 OTU_22 #>   <chr>         <int> <int> <int> <int> <int>  <int>  <int>  <int>  <int>  <int> #> 1 ERR2044662 M…   165   541     8    15     5      4     19      1     61    123 #> 2 ERR2044663 M…   323  1018     5    31    10      2     30      1     83    296 #> 3 ERR2044664 M…    51   351    41   590     7     24    377     NA      2    209 #> 4 ERR2044665 A…    70   115    15   133     3     11    102      1     30    308 #> 5 ERR2044666 A…   134   241    14   174    10     10     83      1     48    405 #> 6 ERR2044667 A…   216    NA   146    NA    16    136     NA     NA      5     NA #> 7 ERR2044669 J…    11    NA    14   173     8     12     19      2    108    183 #> 8 ERR2044668 J…    NA   177    NA    12    NA     NA      4      2    132    165 #> 9 ERR2044670 J…    NA     7    NA     2    NA     NA      1      1     12     12 #> # ℹ 512 more variables: OTU_23 <int>, OTU_26 <int>, OTU_29 <int>, OTU_30 <int>, #> #   OTU_31 <int>, OTU_39 <int>, OTU_40 <int>, OTU_44 <int>, OTU_47 <int>, #> #   OTU_48 <int>, OTU_57 <int>, OTU_58 <int>, OTU_66 <int>, OTU_70 <int>, #> #   OTU_76 <int>, OTU_89 <int>, OTU_91 <int>, OTU_92 <int>, OTU_95 <int>, #> #   OTU_97 <int>, OTU_99 <int>, OTU_100 <int>, OTU_101 <int>, OTU_103 <int>, #> #   OTU_104 <int>, OTU_105 <int>, OTU_106 <int>, OTU_108 <int>, OTU_110 <int>, #> #   OTU_120 <int>, OTU_121 <int>, OTU_122 <int>, OTU_128 <int>, … rb_sp[is.na(rb_sp)] <- 0  # Prepare aesthetics rb_env <- rb_env %>%    mutate(col_month = case_when(Month == \"March\" ~ qualitative_colors[1],                                Month == \"April\" ~ qualitative_colors[2],                                TRUE ~ qualitative_colors[3])) %>%    mutate() cca_plot_rare_biosphere <-    cca(rb_sp[,-1], display = \"sites\", scale = TRUE) %>%    plot(display = \"sites\", type = \"p\", main = \"Rare biosphere\") # cca_plot_rare_biosphere #> $sites #>             CA1        CA2 #> sit1 -0.7896653  0.8503868 #> sit2 -0.8239607  0.9143530 #> sit3 -0.2497625 -1.1717369 #> sit4 -0.3886150 -1.0134637 #> sit5 -0.7702444  0.1222861 #> sit6 -0.5394403 -3.0662464 #> sit7  0.9769221 -0.3825371 #> sit8  1.6462283  0.3933325 #> sit9  1.5573013  0.3989370 #>  #> attr(,\"class\") #> [1] \"ordiplot\" points(cca_plot_rare_biosphere,        bg = rb_env$col_month,        pch = 21,         col = \"grey\",         cex = 2) # with(rb_env,      ordispider(cca_plot_rare_biosphere,                 Month, lty = \"dashed\", label = TRUE))"},{"path":"https://pascoalf.github.io/ulrb/articles/eco-analysis.html","id":"final-considerations","dir":"Articles","previous_headings":"","what":"Final considerations","title":"Integration of ulrb in a simple microbial ecology workflow","text":"Hopefully, got sense ulrb package can integrated general microbial ecology workflow. course, many questions approached, taxonomy . meant serve example ulrb can trivially integrated data analysis workflow.","code":""},{"path":"https://pascoalf.github.io/ulrb/articles/eco-analysis.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Integration of ulrb in a simple microbial ecology workflow","text":"de Sousa, . G. G., Tomasino, M. P., Duarte, P., Fernández-Méndez, M., Assmy, P., Ribeiro, H., Surkont, J., Leite, R. B., Pereira-Leal, J. B., Torgo, L., & Magalhães, C. (2019). Diversity Composition Pelagic Prokaryotic Protist Communities Thin Arctic Sea-Ice Regime. Microbial Ecology, 78(2), 388–408. Mitchell, . L., Almeida, ., Beracochea, M., Boland, M., Burgin, J., Cochrane, G., Crusoe, M. R., Kale, V., Potter, S. C., Richardson, L. J., Sakharova, E., Scheremetjew, M., Korobeynikov, ., Shlemov, ., Kunyavskaya, O., Lapidus, ., & Finn, R. D. (2019). MGnify: microbiome analysis resource 2020. Nucleic Acids Research, 48(D1), D570–D578. Granskog, M. ., Fer, ., Rinke, ., & Steen, H. (2018). Atmosphere-Ice-Ocean-Ecosystem Processes Thinner Arctic Sea Ice Regime: Norwegian Young Sea ICE (N-ICE2015) Expedition. Journal Geophysical Research: Oceans, 123(3), 1586–1594.","code":""},{"path":"https://pascoalf.github.io/ulrb/articles/explore-classifications.html","id":"explore-alternative-classifications","dir":"Articles","previous_headings":"","what":"Explore alternative classifications","title":"Alternative classifications with ulrb","text":"default, considering microbial communities divided “rare”, “undetermined” “abundant”. division implies partition around medoids algorithm considering k=3, .e. three clusters. However, least three situations might want change number clusters: clusters obtained non-sense; biological/ecological questions requires another division; want fully automated classification. might situations, course. bottom line , depending context specific research data, might just want different number classifications. propose 3 think 3 different classifications work well situations, set stone. tutorial show define_rb() can used different classifications also try go little bit deeper whats behind actual function.","code":""},{"path":"https://pascoalf.github.io/ulrb/articles/explore-classifications.html","id":"index","dir":"Articles","previous_headings":"","what":"Index","title":"Alternative classifications with ulrb","text":"Classical example; Apply 2 classifications: Rare vs Abundant; Apply complicated classification, k>3; k = 1 non-sense; maximum number k ?; Approaches evaluate k; Set k automatically.","code":""},{"path":"https://pascoalf.github.io/ulrb/articles/explore-classifications.html","id":"classical-example","dir":"Articles","previous_headings":"Index","what":"Classical example","title":"Alternative classifications with ulrb","text":"classical example simply use default arguments function define_rb().","code":""},{"path":"https://pascoalf.github.io/ulrb/articles/explore-classifications.html","id":"prepare-data","dir":"Articles","previous_headings":"Index > Classical example","what":"Prepare data","title":"Alternative classifications with ulrb","text":"Just like tutorial vignette(\"ulrb-vignet\"), import, clean tidy dataset using define_rb() function.","code":"# Load raw OTU table from N-ICE data(\"nice_raw\", package = \"ulrb\")  # Change name of first column nice_clean <- rename(nice_raw, Taxonomy = \"X.SampleID\")  # Select 16S rRNA amplicon sequencing samples selected_samples <- c(\"ERR2044662\", \"ERR2044663\", \"ERR2044664\",                       \"ERR2044665\", \"ERR2044666\", \"ERR2044667\",                       \"ERR2044668\", \"ERR2044669\", \"ERR2044670\")  # Add a column with phylogenetic units ID (OTU in this case) nice_clean <- mutate(nice_clean, OTU = paste0(\"OTU_\", row_number()))  # Select relevant collumns nice_clean <- select(nice_clean, selected_samples, OTU, Taxonomy) #> Warning: Using an external vector in selections was deprecated in tidyselect 1.1.0. #> ℹ Please use `all_of()` or `any_of()` instead. #>   # Was: #>   data %>% select(selected_samples) #>  #>   # Now: #>   data %>% select(all_of(selected_samples)) #>  #> See <https://tidyselect.r-lib.org/reference/faq-external-vector.html>. #> This warning is displayed once every 8 hours. #> Call `lifecycle::last_lifecycle_warnings()` to see where this warning was #> generated.  # Separate Taxonomy column into each taxonomic level nice_clean <- separate(nice_clean,                         Taxonomy,                        c(\"Domain\",\"Kingdom\",\"Phylum\",                          \"Class\",\"Order\",\"Family\",                          \"Genus\",\"Species\"),                         sep=\";\") #> Warning: Expected 8 pieces. Missing pieces filled with `NA` in 912 rows [1, 2, 4, 5, 6, #> 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, ...].  # Remove Kingdom column, because it is not used for prokaryotes nice_clean <- select(nice_clean, -Kingdom)  # Remove eukaryotes nice_clean <- filter(nice_clean, Domain != \"sk__Eukaryota\")  # Remove unclassified OTUs at phylum level nice_clean <- filter(nice_clean, !is.na(Phylum))  # Simplify name nice <- nice_clean  # Tidy data nice_tidy <- prepare_tidy_data(nice,                                 sample_names = selected_samples,                                 samples_in = \"cols\")"},{"path":"https://pascoalf.github.io/ulrb/articles/explore-classifications.html","id":"default-is-k-3","dir":"Articles","previous_headings":"Index > Classical example","what":"Default is k = 3","title":"Alternative classifications with ulrb","text":"default settings can interpreted division “rare”, “undetermined” “abundant” species. can see meaning division standard Rank Abundance Curve (RAC). Let’s start single sample:  look samples , use centrality metric. Note low number samples can chose use grid, plot samples; wont work high number samples. centrality metric, however, able see number samples single plot.","code":"rb_default <- define_rb(nice_tidy) #> Joining with `by = join_by(Sample, Level)` plot_ulrb_clustering(rb_default,                       sample_id = \"ERR2044662\",                      taxa_col = \"OTU\",                      log_scaled = TRUE) #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`). plot_ulrb_clustering(rb_default,                       taxa_col = \"OTU\",                      log_scaled = TRUE,                      plot_all = TRUE) #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`)."},{"path":"https://pascoalf.github.io/ulrb/articles/explore-classifications.html","id":"apply-2-classifications-rare-vs-abundant","dir":"Articles","previous_headings":"Index","what":"Apply 2 classifications: Rare vs Abundant","title":"Alternative classifications with ulrb","text":"can exactly thing , “rare” “abundant” classifications, set k = 2. Note explicitly set k = 2 define_rb() function, instead, specify classification vector. classification vector can anything, context k = 2, meaning “rare” “abundant” species; call “class1” “class2”, whatever want. Behind scenes, function define_rb() calculate size classification vector estimate k. , classification vector “rare” “abundant”, length 2, k = 2; Likewise, default parameter set classification_vector = c(“Rare”, “Undetermined”, “Abundant”), length = 3 k = 3. apply new classification scheme change classification_vector argument: can see clustering result just like .  can compare two options directly:  recommend using k = 2, implies hard distinction rare abundant taxa. consider always intermediate undetermined group, otherwise, always phylogenetic units similar abundance scores, opposing classifications, misleading. details reasoning, see Pascoal et al., 2023 (manuscript preparation).","code":"rb_k2 <- define_rb(nice_tidy, classification_vector = c(\"Rare\", \"Abundant\")) #> Joining with `by = join_by(Sample, Level)` plot_ulrb_clustering(rb_k2,                      taxa_col = \"OTU\",                      plot_all = TRUE,                       log_scaled = TRUE,                       colors = c(\"#009E73\", \"#F0E442\")) #> Warning: Removed 177 rows containing missing values or values outside the scale range #> (`geom_segment()`). gridExtra::grid.arrange(   plot_ulrb_clustering(rb_default,                       taxa_col = \"OTU\",                      log_scaled = TRUE,                      plot_all = TRUE),   plot_ulrb_clustering(rb_k2,                      taxa_col = \"OTU\",                      plot_all = TRUE,                       log_scaled = TRUE,                       colors = c(\"#009E73\", \"#F0E442\")),   nrow = 1 ) #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`). #> Warning: Removed 177 rows containing missing values or values outside the scale range #> (`geom_segment()`)."},{"path":"https://pascoalf.github.io/ulrb/articles/explore-classifications.html","id":"apply-more-complicated-classification-k3","dir":"Articles","previous_headings":"Index","what":"Apply more complicated classification, k>3","title":"Alternative classifications with ulrb","text":"Lets suppose want distinguish microbial community following groups: (e.g. ) 1) rare; 2) rare; 3) abundant; 4) abundant. : (e.g. B) 1) rare; 2) rare; 4) undetermined; 5) abundant; 6) abundant. even … Hopefully, get idea, point just change classification vector. Lets see e.g. . First select new classification vector, 4 different classifications, thus (implicitly) k = 4.   Note acceptable interpretation data! Hopefully already intuition change classifications wish. Let’s e.g. B, k = 5, includes 5 different classifications.","code":"# rb_k4 <- define_rb(nice_tidy,                     classification_vector = c(\"very rare\", \"rare\", \"abundant\", \"very abundant\")) #> Joining with `by = join_by(Sample, Level)` # # One sample as example plot_ulrb(rb_k4,           sample_id = \"ERR2044662\",            taxa_col = \"OTU\",           colors = c(\"#009E73\", \"#F0E442\", \"grey\",\"#CC79A7\"),           log_scaled = TRUE) #> Warning: Removed 208 rows containing missing values or values outside the scale range #> (`geom_segment()`). #> Removed 208 rows containing missing values or values outside the scale range #> (`geom_segment()`). # all samples plot_ulrb(rb_k4,           taxa_col = \"OTU\",           colors = c(\"#009E73\", \"#F0E442\", \"grey\",\"#CC79A7\"),           log_scaled = TRUE,           plot_all = TRUE) #> Warning: Removed 208 rows containing missing values or values outside the scale range #> (`geom_segment()`). #> Removed 208 rows containing missing values or values outside the scale range #> (`geom_segment()`). # rb_k5 <- define_rb(nice_tidy,                     classification_vector = c(\"very rare\", \"rare\", \"undetermined\", \"abundant\", \"very abundant\")) #> Joining with `by = join_by(Sample, Level)` # One sample as example plot_ulrb(rb_k5,           sample_id = \"ERR2044662\",            taxa_col = \"OTU\",           colors = qualitative_colors[1:5],           log_scaled = TRUE) #> Warning: Removed 213 rows containing missing values or values outside the scale range #> (`geom_segment()`). #> Removed 213 rows containing missing values or values outside the scale range #> (`geom_segment()`). # All samples plot_ulrb(rb_k5,           taxa_col = \"OTU\",           colors = qualitative_colors[1:5],           log_scaled = TRUE,           plot_all = TRUE) #> Warning: Removed 213 rows containing missing values or values outside the scale range #> (`geom_segment()`). #> Removed 213 rows containing missing values or values outside the scale range #> (`geom_segment()`)."},{"path":"https://pascoalf.github.io/ulrb/articles/explore-classifications.html","id":"why-k-1-is-non-sense","dir":"Articles","previous_headings":"Index","what":"Why k = 1 is non-sense","title":"Alternative classifications with ulrb","text":"values k (mathematically) possible, non-sense. Consider, example, k = 1. situation, perfectly possible mathematical point view, .e simply cluster observations single classification. However, meaningless gives extra information community. Additionally, point view rare biosphere, important keep mind one phylogenetic unit can considered “rare” relatively phylogenetic units within community. Thus, context, k = 1 self-contradictory. Despite , keep mind making assumption thing “rare biosphere”. naive assumption caries another assumption within , phylogenetic units sufficiently different abundance relative one another form distinct clusters. fact, don’t think anyone found environmental microbial community constituted phylogenetic units exactly (approximately) abundance score. case, say species neither rare abundant, classification self-contradictory. can thing , setting classification vector just “rare” ’ll see possible, meaningless. ## maximum value k ? maximum value k? set limitations inherent algorithm , case partition around medoids (k-medoids). maximum number groups divide observations must less total observations. Meaning maximum limit, possible observation group. means possible maximum value k equal number different phylogenetic units, .e. phylogenetic unit classification. However, try , get error. several phylogenetic units exactly abundance, specially rare biosphere. Thus, phylogenetic units can never belong different classifications (separating phylogenetic units abundance, phylogenetic units abundance must belong group). means maximum value k equal number different abundance scores, lower number total observations. several samples, maximum value k differ sample (even apply normalization). apply maximum k samples , calculate maximum k samples, select minimum , one working . Just like k = 1, maximum value k meaningless. Even , mathematically can, give additional information. Lets illustrate maximum k one sample: ’m going plot figure, need 71 different colors! really point, just show possible. data wrangling easily samples, number samples. really something ever context rare biosphere studies.","code":"# rb_k1 <- define_rb(nice_tidy, classification_vector = c(\"rare\")) #> Joining with `by = join_by(Sample, Level)` plot_ulrb_clustering(rb_k1,                       taxa_col = \"OTU\",                       colors = \"green4\",                       plot_all = TRUE,                       log_scaled = TRUE) #> Warning: Removed 168 rows containing missing values or values outside the scale range #> (`geom_segment()`). rb_sample1 <- nice_tidy %>% filter(Sample == \"ERR2044662\")  # Calculate maximum k max_k_sample1 <- rb_sample1 %>% pull(Abundance) %>% unique() %>% length() # max_k_sample1 #> [1] 71 # Improvise a classification vector for maximum k # that is just any vector with the same length classification_vector_max_k_sample1 <- seq_along(1:max_k_sample1) # rb_sample1_max_k <-    define_rb(rb_sample1,             classification_vector = classification_vector_max_k_sample1) #> Joining with `by = join_by(Sample, Level)` #> Warning in define_rb(rb_sample1, classification_vector = #> classification_vector_max_k_sample1): 25 samples got a bad Silhouette score. #> Consider changing the number of classifications. #> If half the observations within a classification are below 0.5 Silhouette score, we consider that the clustering was 'Bad'. #> Check 'Evaluation' collumn for more details. # rb_sample1_max_k %>% select(OTU, Classification, Abundance) %>% head(10) #> Adding missing grouping variables: `Sample` #> # A tibble: 10 × 4 #> # Groups:   Sample, Classification [3] #>    Sample     OTU     Classification Abundance #>    <chr>      <chr>   <fct>              <int> #>  1 ERR2044662 OTU_2   44                   165 #>  2 ERR2044662 OTU_5   58                   541 #>  3 ERR2044662 OTU_6   8                      8 #>  4 ERR2044662 OTU_29  8                      8 #>  5 ERR2044662 OTU_30  8                      8 #>  6 ERR2044662 OTU_244 8                      8 #>  7 ERR2044662 OTU_260 8                      8 #>  8 ERR2044662 OTU_313 8                      8 #>  9 ERR2044662 OTU_329 8                      8 #> 10 ERR2044662 OTU_380 8                      8"},{"path":"https://pascoalf.github.io/ulrb/articles/explore-classifications.html","id":"approaches-to-evaluate-k","dir":"Articles","previous_headings":"Index","what":"Approaches to evaluate k","title":"Alternative classifications with ulrb","text":"want compare possible values k? , , just candidates? compare values k, useful metrics implemented ulrb package: Average Silhouette score (cluster density); Davies-Bouldin index (cluster separation); Calinski-Harabasz index (cluster definition). metrics evaluates different aspects one clustering result; thus, can calculate clustering obtained value k. comparing values obtained k, can select k got best score. , consider following: Average Silhouette Score: Select maximum value best k; Davies-Bouldin index: Select minimum value best k; Calinski-Harabasz index: Select maximum value best k. straight forward way evaluate reasonable range k’s using function suggest_k(). function includes argument detailed results, give results three indices, k = 3 k = 10. don’t recommend testing k’s outside range purpose defining rare biosphere, can analyze possible k’s (just change range argument). another group k’s, range = 10:20","code":"suggest_k(nice_tidy, detailed = TRUE)   #> [[1]] #> [1] \"This list contains several details that might help you decide a k parameter.\" #>  #> [[2]] #>                      Score                 Criteria                     Details #> 1     Davies-Bouldin index Minimum value for best k Measures cluster separation #> 2  Calinski-Harabasz index Maximum value for best k Measures cluster definition #> 3 Average Silhouette Score Maximum value for best k    Measures cluster density #>  #> $SamplesSummary #> [1] \"You study has 9 samples. For each one we calculated all indices obtained for each k, from 3 to 10\" #>  #> $DaviesBouldin #> # A tibble: 9 × 3 #>   Sample          CH     k #>   <chr>        <dbl> <int> #> 1 ERR2044662  30332.    10 #> 2 ERR2044663  42150.    10 #> 3 ERR2044664 296091.    10 #> 4 ERR2044665  31908.    10 #> 5 ERR2044666  88804.    10 #> 6 ERR2044667  17792.    10 #> 7 ERR2044669  35405.    10 #> 8 ERR2044668  75615.    10 #> 9 ERR2044670  18276.     9 #>  #> $CalinskiHarabasz #> # A tibble: 9 × 3 #>   Sample          CH     k #>   <chr>        <dbl> <int> #> 1 ERR2044662  30332.    10 #> 2 ERR2044663  42150.    10 #> 3 ERR2044664 296091.    10 #> 4 ERR2044665  31908.    10 #> 5 ERR2044666  88804.    10 #> 6 ERR2044667  17792.    10 #> 7 ERR2044669  35405.    10 #> 8 ERR2044668  75615.    10 #> 9 ERR2044670  18276.     9 #>  #> $averageSilhouette #> # A tibble: 9 × 3 #>   Sample     average_Silhouette     k #>   <chr>                   <dbl> <int> #> 1 ERR2044662              0.952     3 #> 2 ERR2044663              0.955     3 #> 3 ERR2044664              0.970     3 #> 4 ERR2044665              0.915     3 #> 5 ERR2044666              0.965     3 #> 6 ERR2044667              0.874     3 #> 7 ERR2044669              0.913     5 #> 8 ERR2044668              0.951     4 #> 9 ERR2044670              0.932     3 suggest_k(nice_tidy, detailed = TRUE, range = 10:20)   #> [[1]] #> [1] \"This list contains several details that might help you decide a k parameter.\" #>  #> [[2]] #>                      Score                 Criteria                     Details #> 1     Davies-Bouldin index Minimum value for best k Measures cluster separation #> 2  Calinski-Harabasz index Maximum value for best k Measures cluster definition #> 3 Average Silhouette Score Maximum value for best k    Measures cluster density #>  #> $SamplesSummary #> [1] \"You study has 9 samples. For each one we calculated all indices obtained for each k, from 10 to 20\" #>  #> $DaviesBouldin #> # A tibble: 9 × 3 #>   Sample           CH     k #>   <chr>         <dbl> <int> #> 1 ERR2044662  234158.    20 #> 2 ERR2044663  302032.    20 #> 3 ERR2044664 2004343.    20 #> 4 ERR2044665  230118.    20 #> 5 ERR2044666  316479.    20 #> 6 ERR2044667  190069.    20 #> 7 ERR2044669  183647.    19 #> 8 ERR2044668  418496.    18 #> 9 ERR2044670  212691.    19 #>  #> $CalinskiHarabasz #> # A tibble: 9 × 3 #>   Sample           CH     k #>   <chr>         <dbl> <int> #> 1 ERR2044662  234158.    20 #> 2 ERR2044663  302032.    20 #> 3 ERR2044664 2004343.    20 #> 4 ERR2044665  230118.    20 #> 5 ERR2044666  316479.    20 #> 6 ERR2044667  190069.    20 #> 7 ERR2044669  183647.    19 #> 8 ERR2044668  418496.    18 #> 9 ERR2044670  212691.    19 #>  #> $averageSilhouette #> # A tibble: 9 × 3 #>   Sample     average_Silhouette     k #>   <chr>                   <dbl> <int> #> 1 ERR2044662              0.770    10 #> 2 ERR2044663              0.800    12 #> 3 ERR2044664              0.773    10 #> 4 ERR2044665              0.789    11 #> 5 ERR2044666              0.781    10 #> 6 ERR2044667              0.791    11 #> 7 ERR2044669              0.748    12 #> 8 ERR2044668              0.799    13 #> 9 ERR2044670              0.747    14"},{"path":"https://pascoalf.github.io/ulrb/articles/explore-classifications.html","id":"fine-grained-analysis","dir":"Articles","previous_headings":"Index > Approaches to evaluate k","what":"Fine grained analysis","title":"Alternative classifications with ulrb","text":"can look particular metrics specific samples. , made several helper functions: check_avgSil() calculate average silhouette score; check_DB() calculate Davies-Bouldin index; check_CH()calculate Calinski-Harabasz index. can also calculate time one sample evaluate_sample_k() samples evaluate_k(). Let’s look several examples, using default range k = 3 k = 10:  last plot, value k represents clustering result. information, select k = 3 (just like default option), highest average Silhouette score. can repeat indices:   Note best k changed depending metric selected. Thus, sample 1 (ERR2044662), best k : - 3 based average Silhouette scores; - 4 based Davies-Bouldin index; - 10 based Calinski-Harabasz index. can see compare directly evaluate_sample_k():  ulrb method assumes samples independent , means results one sample, different samples. Thus, look samples time, centrality metrics. , can use function evaluate_k():","code":"## One sample # To get values check_avgSil(nice_tidy, sample_id = selected_samples[1]) #> [1] 0.9521452 0.8820316 0.8561774 0.8398216 0.8479872 0.7843358 0.7740169 #> [8] 0.7701163  # To plot results check_avgSil(nice_tidy, sample_id = selected_samples[1], with_plot = TRUE) ## Davie-Boulding index # To get values check_DB(nice_tidy, sample_id = selected_samples[1]) #> [1] 0.3721866 0.5271704 0.4131651 0.4292696 0.3350836 0.3892966 0.3948026 #> [8] 0.3294451  # To plot results check_DB(nice_tidy, sample_id = selected_samples[1], with_plot = TRUE) ## Calinski-Harabasz index # To get values check_CH(nice_tidy, sample_id = selected_samples[1]) #> [1]  1821.426  2054.887  4933.956  5465.134 17589.032 17179.809 18083.313 #> [8] 30332.345  # To plot results check_CH(nice_tidy, sample_id = selected_samples[1], with_plot = TRUE) evaluate_sample_k(nice_tidy, sample_id = selected_samples[1], with_plot = TRUE) ## To get values evaluate_k(nice_tidy) #> # A tibble: 72 × 6 #> # Groups:   Sample [9] #>    Sample     data                   DB     CH average_Silhouette     k #>    <chr>      <list>              <dbl>  <dbl>              <dbl> <int> #>  1 ERR2044662 <tibble [187 × 10]> 0.372  1821.              0.952     3 #>  2 ERR2044662 <tibble [187 × 10]> 0.527  2055.              0.882     4 #>  3 ERR2044662 <tibble [187 × 10]> 0.413  4934.              0.856     5 #>  4 ERR2044662 <tibble [187 × 10]> 0.429  5465.              0.840     6 #>  5 ERR2044662 <tibble [187 × 10]> 0.335 17589.              0.848     7 #>  6 ERR2044662 <tibble [187 × 10]> 0.389 17180.              0.784     8 #>  7 ERR2044662 <tibble [187 × 10]> 0.395 18083.              0.774     9 #>  8 ERR2044662 <tibble [187 × 10]> 0.329 30332.              0.770    10 #>  9 ERR2044663 <tibble [220 × 10]> 0.391  1491.              0.955     3 #> 10 ERR2044663 <tibble [220 × 10]> 0.516  1495.              0.891     4 #> # ℹ 62 more rows  ## To plot evaluate_k(nice_tidy, with_plot = TRUE) #> No summary function supplied, defaulting to `mean_se()` #> No summary function supplied, defaulting to `mean_se()` #> No summary function supplied, defaulting to `mean_se()`"},{"path":"https://pascoalf.github.io/ulrb/articles/explore-classifications.html","id":"automatic-k-selection","dir":"Articles","previous_headings":"Index","what":"Automatic k selection","title":"Alternative classifications with ulrb","text":"can decide k use based metrics, aware measure different aspects clustering results. function suggest_k(), default, : calculate best k, based average Silhouette score, sample; calculate average best k across samples; return best k integer. Thus, default output suggest_k() single integer; used define_rb() function automatic k decision. Instead average Silhouette score, can select another index (Davies-Bouldin Calinski-Harabasz), function suggest_k() return best k based index. Let’s see examples:","code":"# default option with average Silhouette score suggest_k(nice_tidy) #> [1] 3  # best k for Davies-Bouldin suggest_k(nice_tidy, index = \"Davies-Bouldin\") #> [1] 6  # best k for Calinski-Harabasz suggest_k(nice_tidy, index = \"Calinski-Harabasz\") #> [1] 9"},{"path":"https://pascoalf.github.io/ulrb/articles/explore-classifications.html","id":"everything-automatic","dir":"Articles","previous_headings":"Index","what":"Everything automatic","title":"Alternative classifications with ulrb","text":"Finally, ability automatically suggest value k, can context definition rarity. , can use default parameters define_rb(), automatic argument set TRUE. Like ,  Naturally, can decide parameters automatic selection k, example, lets suppose want groups phylogenetic units well defined, also want , least, four classifications, 6. two conditions, specify range k values (4:6) evaluation index Calinski-Harabasz index: Note function informed automatic k selected 5. Thus, know need 5 colors standard ulrb plots:  example, automatic option seem give better result default k = 3.","code":"automatic_classification <- define_rb(nice_tidy, automatic = TRUE) #> Automatic option set to TRUE, so classification vector was overwritten #> K= 3 based on Average Silhouette Score. #> Joining with `by = join_by(Sample, Level)`  # Plot automatic result  plot_ulrb(automatic_classification, taxa_col = \"OTU\", plot_all = TRUE) #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`). #> Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`). more_complex_automatic_classification <- define_rb(nice_tidy,                                                     automatic = TRUE,                                                    index = \"Calinski-Harabasz\",                                                    range = 4:6) #> Automatic option set to TRUE, so classification vector was overwritten #> K= 5 based on Calinski-Harabasz. #> Joining with `by = join_by(Sample, Level)` # Plot automatic result plot_ulrb(more_complex_automatic_classification,            plot_all = TRUE,            taxa_col = \"OTU\",            colors = qualitative_colors[1:5],           log_scaled = TRUE) #> Warning: Removed 213 rows containing missing values or values outside the scale range #> (`geom_segment()`). #> Removed 213 rows containing missing values or values outside the scale range #> (`geom_segment()`)."},{"path":"https://pascoalf.github.io/ulrb/articles/explore-classifications.html","id":"how-each-index-behaves-across-all-possible-values-of-k","dir":"Articles","previous_headings":"Index","what":"How each index behaves across all possible values of k?","title":"Alternative classifications with ulrb","text":"last section completion sake necessary study rare biosphere; however, might prove useful interested details unsupervised learning approach. maximum k, just need use evaluate_k() function full range values. (try run code, might take )","code":"# Start by deciding the maximum range across the entire dataset max_k <- nice_tidy %>%     filter(Abundance > 0, !is.na(Abundance)) %>%     group_by(Sample) %>%     summarise(topK = length(unique(Abundance))) %>%     ungroup() %>%     pull(topK) %>%     min() # print maximum number of clusters allowed for all samples in the N-ICE dataset max_k #> [1] 55 evaluate_k(nice_tidy, with_plot = TRUE, range = 2:max_k) #> Warning: Removed 1 row containing non-finite outside the scale range #> (`stat_summary()`). #> No summary function supplied, defaulting to `mean_se()` #> No summary function supplied, defaulting to `mean_se()` #> No summary function supplied, defaulting to `mean_se()`"},{"path":"https://pascoalf.github.io/ulrb/articles/ulrb-vignet.html","id":"unsupervised-learning-based-definition-of-microbial-rare-biosphere","dir":"Articles","previous_headings":"","what":"Unsupervised Learning Based Definition Of Microbial Rare Biosphere","title":"Tutorial to define rare biosphere with ulrb","text":"R package ulrb solves problem definition rarity replacing human decision unsupervised machine learning algorithm (partitioning around medoids, k-medoids). algorithm works type microbiome data, provided abundance score phylogenetic unit. validation method several kinds molecular data environments, please see Pascoal et al., 2023 (preparation). Preliminary results indicate method works oter biological systems, provided abundance table. tutorial illustrate define microbial rare biosphere small, publicly available dataset, Norwegian Young Sea Ice Expedition, 2016 (N-ICE). molecular data amplicon sequencing 16S rRNA gene (sequencing details, see Sousa et al., 2019), raw sequences available European Nucleotide Archive (ENA) accession number ERP024265, processed OTUs MGnify (Mitchell et al.,2019). N-ICE dataset consists 9 samples, collected winter spring transition 2015 fixing vessel drifting ice (Granskog et al., 2018). Samples collected various depths (5m 250m) ice drifted across different regions, DNA collected 16S amplicon sequencing metagenomes (de Sousa et al., 2019); bioinformatic processing reads performed Mgnify platform (v5) (Mitchel et al., 2020). tutorial using OTU table downloaded link https://www.ebi.ac.uk/metagenomics/studies/MGYS00001922#analysis 06-01-2023 focus solely 16S amplicon data.","code":"library(ulrb) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union library(tidyr) library(ggplot2)"},{"path":"https://pascoalf.github.io/ulrb/articles/ulrb-vignet.html","id":"brief-note-on-nomenclature","dir":"Articles","previous_headings":"Unsupervised Learning Based Definition Of Microbial Rare Biosphere","what":"Brief note on nomenclature","title":"Tutorial to define rare biosphere with ulrb","text":"use term “phylogenetic units” refer highest resolution, distinct unit identified. can species, OTU, ASV, … use term “abundance table” refer table , least, abundance score phylogenetic unit. additional data can added, can OTU table, ASV table… also use term “scale” “scaling”, can also appear literature “normalization”, “transformation”, …","code":""},{"path":"https://pascoalf.github.io/ulrb/articles/ulrb-vignet.html","id":"pre-processing-of-data-prior-to-clustering-algorithm","dir":"Articles","previous_headings":"Unsupervised Learning Based Definition Of Microbial Rare Biosphere","what":"Pre-processing of data prior to clustering algorithm","title":"Tutorial to define rare biosphere with ulrb","text":"package ulrb require abundance table tidy (long) format, column abundance score used another column samples. additional columns allowed. Regarding abundance score, scaling abundance score vignette, k-medoids algorithm applied “per sample” values abundance score. means scaling, e.g. relative abundance, center log-ratio, … effect algorithm, distance values observations remain . However, algorithm applied variables (abundance), scaling make difference. Thus, consider best use absolute values tutorial, avoid misleading reader thinking scaling done. Notwithstanding, publication purposes purposes data processing steps, might make sense apply sort scaling. long number observations, .e. number phylogenetic units, , distance . user decides apply quality filtering abundance table, like rarefaction, done using clustering method. summary, algorithm applied final, clean abundance table, abundance score.","code":""},{"path":"https://pascoalf.github.io/ulrb/articles/ulrb-vignet.html","id":"load-and-clean-abundance-table","dir":"Articles","previous_headings":"Unsupervised Learning Based Definition Of Microbial Rare Biosphere > Pre-processing of data prior to clustering algorithm","what":"Load and clean abundance table","title":"Tutorial to define rare biosphere with ulrb","text":"","code":"# Load raw OTU table from N-ICE data(\"nice_raw\", package = \"ulrb\")  # Change name of first column nice_clean <- rename(nice_raw, Taxonomy = \"X.SampleID\")  # Select 16S rRNA amplicon sequencing samples selected_samples <- c(\"ERR2044662\", \"ERR2044663\", \"ERR2044664\",\"ERR2044665\", \"ERR2044666\", \"ERR2044667\",\"ERR2044668\", \"ERR2044669\", \"ERR2044670\")  # Add a column with phylogenetic units ID (OTU in this case) nice_clean <- mutate(nice_clean, OTU = paste0(\"OTU_\", row_number()))  # Select relevant columns nice_clean <- select(nice_clean, selected_samples, OTU, Taxonomy) #> Warning: Using an external vector in selections was deprecated in tidyselect 1.1.0. #> ℹ Please use `all_of()` or `any_of()` instead. #>   # Was: #>   data %>% select(selected_samples) #>  #>   # Now: #>   data %>% select(all_of(selected_samples)) #>  #> See <https://tidyselect.r-lib.org/reference/faq-external-vector.html>. #> This warning is displayed once every 8 hours. #> Call `lifecycle::last_lifecycle_warnings()` to see where this warning was #> generated.  # Separate Taxonomy column into each taxonomic level nice_clean <- separate(nice_clean, Taxonomy, c(\"Domain\",\"Kingdom\",\"Phylum\",\"Class\",\"Order\",\"Family\",\"Genus\",\"Species\"),sep=\";\") #> Warning: Expected 8 pieces. Missing pieces filled with `NA` in 912 rows [1, 2, 4, 5, 6, #> 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, ...].  # Remove Kingdom column, because it is not used for prokaryotes nice_clean <- select(nice_clean, -Kingdom)  # Remove eukaryotes nice_clean <- filter(nice_clean, Domain != \"sk__Eukaryota\")  # Remove unclassified OTUs at phylum level nice_clean <- filter(nice_clean, !is.na(Phylum))  # Simplify name nice <- nice_clean  # Quick look at the table head(nice) #>   ERR2044662 ERR2044663 ERR2044664 ERR2044665 ERR2044666 ERR2044667 ERR2044668 #> 1        165        323         51         70        134        216          0 #> 2          0          0          1          0          0          1          0 #> 3          0          0          1          2          2          6          0 #> 4        541       1018        351        115        241       1633        177 #> 5          8          5         41         15         14        146          0 #> 6         15         31        590        133        174       1814         12 #>   ERR2044669 ERR2044670   OTU      Domain            Phylum #> 1         11          0 OTU_2 sk__Archaea  p__Euryarchaeota #> 2          0          0 OTU_3 sk__Archaea  p__Euryarchaeota #> 3          0          0 OTU_4 sk__Archaea  p__Euryarchaeota #> 4       1371          7 OTU_5 sk__Archaea  p__Euryarchaeota #> 5         14          0 OTU_6 sk__Archaea p__Thaumarchaeota #> 6        173          2 OTU_7 sk__Archaea p__Thaumarchaeota #>                       Class                       Order Family #> 1 c__Candidatus_Poseidoniia                        <NA>   <NA> #> 2 c__Candidatus_Poseidoniia o__Candidatus_Poseidoniales    f__ #> 3           c__Halobacteria          o__Halobacteriales   <NA> #> 4         c__Thermoplasmata                        <NA>   <NA> #> 5                      <NA>                        <NA>   <NA> #> 6                       c__                         o__    f__ #>                            Genus                                        Species #> 1                           <NA>                                           <NA> #> 2                            g__ s__Marine_group_II_euryarchaeote_REDSEA-S03_B6 #> 3                           <NA>                                           <NA> #> 4                           <NA>                                           <NA> #> 5                           <NA>                                           <NA> #> 6 g__Candidatus_Nitrosopelagicus                                           <NA>"},{"path":"https://pascoalf.github.io/ulrb/articles/ulrb-vignet.html","id":"transform-abundance-table-into-tidylong-format","dir":"Articles","previous_headings":"Unsupervised Learning Based Definition Of Microbial Rare Biosphere > Pre-processing of data prior to clustering algorithm","what":"Transform abundance table into tidy/long format","title":"Tutorial to define rare biosphere with ulrb","text":"Now cleaned OTU table, can transform tidy format. can part order according data format. made function prepare_tidy_data() help transform two common data formats abundance tables: phylogenetic units rows, samples columns; phylogenetic units columns, samples rows. example, data.frame phylogenetic units rows samples various columns, tidy format. need collapse columns samples single “Abundance” “Samples” column, variable corresponds single column, .e. tidy. just need apply prepare_tidy_data() function cleaned data. Note need specify format abundance table . example, samples different columns, set argument samples_in “cols”; opposite situation, samples rows, set samples_in “rows”. function optional use really verify transforming data correctly, data might different standard examples.","code":"nice_tidy <- prepare_tidy_data(nice, sample_names = selected_samples, samples_in = \"cols\")"},{"path":"https://pascoalf.github.io/ulrb/articles/ulrb-vignet.html","id":"apply-definition-of-rare-biosphere-with-unsupervised-learning","dir":"Articles","previous_headings":"Unsupervised Learning Based Definition Of Microbial Rare Biosphere","what":"Apply definition of rare biosphere with unsupervised learning","title":"Tutorial to define rare biosphere with ulrb","text":"Now ready use central function package ulrb, define_rb(). function add new columns input data.frame, automatically deciding classification phylogenetic unit, per sample, means partition around medoids algorithm. algorithm run pam() function cluster package. output clusters, translate classifications, provides statistical scores interpret robustness clusters formed. statistics, select silhouette scores, used evaluate results later . Additionally, data.frame include nested list output pam(), experienced users analyze necessary. Regarding classifications, setting default “rare”, “undetermined” “abundant”, based Pascoal et al., 2023 (manuscript preparation). However, user can set vector classifications, long follow rules number clusters, k, pam(). Meaning, number classifications can’t number distinct observations data. practice concern, think researchers either use default, “rare” vs “abundant”, nuanced “rare”, “rare”, “abundant”, “abundant”. point classification can decided study study context. Since default output includes many columns support classification obtained, added argument, simplified, TRUE return simplified version output, without silhouette scores, just final classification, plus input data. use default, simplified = FALSE.","code":"classified_table <- define_rb(nice_tidy) #> Joining with `by = join_by(Sample, Level)`  # Quick output check colnames(classified_table) #>  [1] \"Sample\"                   \"Classification\"           #>  [3] \"OTU\"                      \"Domain\"                   #>  [5] \"Phylum\"                   \"Class\"                    #>  [7] \"Order\"                    \"Family\"                   #>  [9] \"Genus\"                    \"Species\"                  #> [11] \"Abundance\"                \"pam_object\"               #> [13] \"Level\"                    \"Silhouette_scores\"        #> [15] \"Cluster_median_abundance\" \"median_Silhouette\"        #> [17] \"Evaluation\"  classified_table %>%    select(OTU, Sample, Abundance,           Classification, Silhouette_scores, Cluster_median_abundance,           pam_object) %>%    head() #> # A tibble: 6 × 7 #> # Groups:   Sample, Classification [1] #>   OTU   Sample Abundance Classification Silhouette_scores Cluster_median_abund…¹ #>   <chr> <chr>      <int> <fct>                      <dbl>                  <dbl> #> 1 OTU_2 ERR20…       165 Rare                       0.985                    5.5 #> 2 OTU_5 ERR20…       541 Rare                       0.985                    5.5 #> 3 OTU_6 ERR20…         8 Rare                       0.985                    5.5 #> 4 OTU_7 ERR20…        15 Rare                       0.985                    5.5 #> 5 OTU_8 ERR20…         5 Rare                       0.985                    5.5 #> 6 OTU_… ERR20…         4 Rare                       0.985                    5.5 #> # ℹ abbreviated name: ¹​Cluster_median_abundance #> # ℹ 1 more variable: pam_object <list>"},{"path":"https://pascoalf.github.io/ulrb/articles/ulrb-vignet.html","id":"fully-automated-version","dir":"Articles","previous_headings":"Unsupervised Learning Based Definition Of Microbial Rare Biosphere > Apply definition of rare biosphere with unsupervised learning","what":"Fully automated version","title":"Tutorial to define rare biosphere with ulrb","text":"previous example, still one level subjective decision, number classifications use (e.g. “rare”, “undetermined” “abundant” k = 3). However, added option main function, define_rb(), allows automatic decision number clusters. automation works assumption range good k values lies 3 10 (see Pascoal et al., 2023 reasoning behind ). vignette(\"explore-classifications\"), explain detail automation works can make decision regarding k, using several metrics.","code":"# Simple automation example define_rb(nice_tidy, automatic =  TRUE) #> Automatic option set to TRUE, so classification vector was overwritten #> K= 3 based on Average Silhouette Score. #> Joining with `by = join_by(Sample, Level)` #> # A tibble: 2,177 × 17 #> # Groups:   Sample, Classification [27] #>    Sample    Classification OTU   Domain Phylum Class Order Family Genus Species #>    <chr>     <fct>          <chr> <chr>  <chr>  <chr> <chr> <chr>  <chr> <chr>   #>  1 ERR20446… 1              OTU_2 sk__A… p__Eu… c__C… NA    NA     NA    NA      #>  2 ERR20446… 1              OTU_5 sk__A… p__Eu… c__T… NA    NA     NA    NA      #>  3 ERR20446… 1              OTU_6 sk__A… p__Th… NA    NA    NA     NA    NA      #>  4 ERR20446… 1              OTU_7 sk__A… p__Th… c__   o__   f__    g__C… NA      #>  5 ERR20446… 1              OTU_8 sk__A… p__Th… c__   o__N… NA     NA    NA      #>  6 ERR20446… 1              OTU_… sk__A… p__Th… c__   o__N… f__Ni… g__N… NA      #>  7 ERR20446… 1              OTU_… sk__B… p__Ac… NA    NA    NA     NA    NA      #>  8 ERR20446… 1              OTU_… sk__B… p__Ac… c__A… o__A… NA     NA    NA      #>  9 ERR20446… 1              OTU_… sk__B… p__Ac… NA    NA    NA     NA    NA      #> 10 ERR20446… 1              OTU_… sk__B… p__Ac… c__A… NA    NA     NA    NA      #> # ℹ 2,167 more rows #> # ℹ 7 more variables: Abundance <int>, pam_object <list>, Level <fct>, #> #   Silhouette_scores <dbl>, Cluster_median_abundance <dbl>, #> #   median_Silhouette <dbl>, Evaluation <chr>"},{"path":"https://pascoalf.github.io/ulrb/articles/ulrb-vignet.html","id":"verify-results","dir":"Articles","previous_headings":"Unsupervised Learning Based Definition Of Microbial Rare Biosphere","what":"Verify results","title":"Tutorial to define rare biosphere with ulrb","text":"good practice check results unsupervised learning look sane. help task, made group functions help researchers understand need less classifications (change value k), algorithm just doesn’t work. hard rule verify unsupervised learning, results look reasonable follow expectations. seen results method consistent previous definitions rarity, example, phylogenetic units rare abundant, avoid introducing human decision points rare abundant. plots (1) Rank Abundance Curve (2) Silhouette plots. first helpful microbial ecologists, second helpful data scientists. plots made available function plot_ulrb() (verify clustering Silhouette score); plot_ulrb_clustering() plot_ulrb_silhouette(), verify clustering Silhouette, respectively.","code":""},{"path":"https://pascoalf.github.io/ulrb/articles/ulrb-vignet.html","id":"rank-abunddance-curve-rac-to-verify-clustering","dir":"Articles","previous_headings":"Unsupervised Learning Based Definition Of Microbial Rare Biosphere > Verify results","what":"(1) Rank Abunddance Curve (RAC) to verify clustering","title":"Tutorial to define rare biosphere with ulrb","text":"RAC common tool microbial ecology describe detection limits different methods distribution species abundance (Pedrós-Alió, 2012) - ranks species least abundant, resulting species high abundance “long-tail” low abundance species (called “rare biosphere”). However, objective method decide “long-tail” begins. ulrb method considers terms “rare” “abundant” relative, .e. one phylogenetic unit rare , , compared abundant one (vice-versa). explore consequences assumptions play Pascoal et al., 2023 (manuscript preparation). means method looking beginning “long-tail”, comparing abundance phylogenetic units, clustering accordingly. Thus, plot standard RAC color phylogenetic unit according unsupervised classification, can check unsupervised classification consistent notion rare-biosphere within “long-tail”. , provide function plot_ulrb_clustering(). , abundance score can transformed Log10 scale can applied optionally. ggplot2 functions arguments can used, can also make plots analysis.   RAC obtained, confirm unsupervised classification provides reasonable result. rare biosphere indeed “long-tail”, followed transition region, term “undetermined”, neither rare, abundant, extreme points abundant.","code":"# One sample as example plot_ulrb_clustering(classified_table,                         sample_id = selected_samples[1],                        taxa_col = \"OTU\") +   labs(title = paste(\"Clustering for sample\", selected_samples[1])) #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`). # All samples, with centrality metric plot_ulrb_clustering(classified_table,                      taxa_col = \"OTU\",                       plot_all = TRUE,                       log_scaled = TRUE) +   labs(title = \"Clustering for all samples\") #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`)."},{"path":"https://pascoalf.github.io/ulrb/articles/ulrb-vignet.html","id":"silhouette-plots","dir":"Articles","previous_headings":"Unsupervised Learning Based Definition Of Microbial Rare Biosphere > Verify results","what":"(2) Silhouette plots","title":"Tutorial to define rare biosphere with ulrb","text":"Silhouette plot provides notion coherence points inside cluster. values observation range -1 +1, closer +1, coherent cluster. Usually, observations close +1, low values. rule thumb, values 0.75, clusters strong, many observations close 0, positive, cluster might artificial; negative values, clusters structure. details see documentation functions plot_ulrb_silhouette() check_avgSil(); also refer Chapter 2 “Finding Groups Data: Introduction Cluster Analysis” (Kaufman Rousseuw, 1991), details interpretation Silhouette plots.   expected, points close +1, points falling 0.5.","code":"# One sample as example plot_ulrb_silhouette(classified_table,                      sample_id = selected_samples[1],                      taxa_col = \"OTU\") +   labs(title = paste(\"Silhouette plot of sample\", selected_samples[1])) #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`). # plot_ulrb_silhouette(classified_table,                      sample_id = selected_samples[1],                      taxa_col = \"OTU\",                      plot_all = TRUE) +   labs(title = \"Silhouette plot of all samples\") #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`)."},{"path":"https://pascoalf.github.io/ulrb/articles/ulrb-vignet.html","id":"sanity-check-summary","dir":"Articles","previous_headings":"Unsupervised Learning Based Definition Of Microbial Rare Biosphere","what":"Sanity check summary","title":"Tutorial to define rare biosphere with ulrb","text":"provide function plot_ulrb() wraps around plot_ulrb_clustering() plot_ulrb_silhouette() plot RAC Silhouette plot grid. function works single sample samples.","code":"# For a single sample plot_ulrb(classified_table,           sample_id =  selected_samples[1],           taxa_col = \"OTU\") #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`). #> Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`). # For all samples plot_ulrb(classified_table,           taxa_col = \"OTU\",           plot_all = TRUE)  #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`). #> Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`)."},{"path":"https://pascoalf.github.io/ulrb/articles/ulrb-vignet.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Tutorial to define rare biosphere with ulrb","text":"Pascoal et al., 2023 (manuscript preparation) Granskog, M. ., Fer, ., Rinke, ., & Steen, H. (2018). Atmosphere-Ice-Ocean-Ecosystem Processes Thinner Arctic Sea Ice Regime: Norwegian Young Sea ICE (N-ICE2015) Expedition. Journal Geophysical Research: Oceans, 123(3), 1586–1594. de Sousa, . G. G., Tomasino, M. P., Duarte, P., Fernández-Méndez, M., Assmy, P., Ribeiro, H., Surkont, J., Leite, R. B., Pereira-Leal, J. B., Torgo, L., Magalhães, C. (2019). Diversity Composition Pelagic Prokaryotic Protist Communities Thin Arctic Sea-Ice Regime. Microbial Ecology, 78(2), 388–408. Mitchell, . L., Almeida, ., Beracochea, M., Boland, M., Burgin, J., Cochrane, G., Crusoe, M. R., Kale, V., Potter, S. C., Richardson, L. J., Sakharova, E., Scheremetjew, M., Korobeynikov, ., Shlemov, ., Kunyavskaya, O., Lapidus, ., Finn, R. D. (2019). MGnify: microbiome analysis resource 2020. Nucleic Acids Research, 48, D570–D578. Pedrós-Alió, C. (2012). Rare Bacterial Biosphere. Annual Review Marine Science, 4(1), 449–466. Kaufman, L., & Rousseuw, P. J. (1991). Chapter 2 book Finding Groups Data: Introduction Cluster Analysis. Biometrics, 47(2), 788.","code":""},{"path":"https://pascoalf.github.io/ulrb/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Francisco Pascoal. Author, maintainer. Paula Branco. Author. Luís Torgo. Author. Rodrigo Costa. Author. Catarina Magalhães. Author.","code":""},{"path":"https://pascoalf.github.io/ulrb/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Pascoal F, Branco P, Torgo L, Costa R, Magalhães C (2024). “Definition microbial rare biosphere unsupervised machine learning.” Communications Biology (peer-review).","code":"@Article{,   title = {Definition of the microbial rare biosphere through unsupervised machine learning},   author = {Francisco Pascoal and Paula Branco and Luís Torgo and Rodrigo Costa and Catarina Magalhães},   journal = {Communications Biology (in peer-review)},   year = {2024}, }"},{"path":"https://pascoalf.github.io/ulrb/index.html","id":"ulrb","dir":"","previous_headings":"","what":"Unsupervised Learning Based Definition of Microbial Rare Biosphere","title":"Unsupervised Learning Based Definition of Microbial Rare Biosphere","text":"R package ulrb stands Unsupervised Learning Based Definition Microbial Rare Biosphere. name suggests, applies unsupervised learning principles define rare biosphere. specifically, partitioning around medoids (k-medoids) algorithm used divide species within sample clusters. clusters ordered based user-defined classification vector. default, method classifies species : “rare”, “undetermined” “abundant”. alternative, user can change number classifications. , ulrb includes functions help user decide number classifications (k), also possible ulrb automatically decide number clusters. Besides clustering, uleb includes functions help evaluate clustering quality (e.g. average Silhouette score). detailed theory behind reasoning definition microbial rare biosphere, results applications, see paper Pascoal et al., 2024 (peer-review). details R functions used data wrangling please see package documentation. tutorials documentation ulrb package, visit website: link. Note: article cite ulrb undergoind peer-review Communications Biology journal","code":""},{"path":"https://pascoalf.github.io/ulrb/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Unsupervised Learning Based Definition of Microbial Rare Biosphere","text":"install last stable version, use: want install last version available GitHub, use: working CRAN publication. provide instructions CRAN installation.","code":"install.packages(\"ulrb\") #> Installing package into '/tmp/Rtmp3lIXqn/temp_libpath1b67278d2981' #> (as 'lib' is unspecified) # install.packages(\"devtools\") devtools::install_github(\"pascoalf/ulrb\")"},{"path":"https://pascoalf.github.io/ulrb/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Unsupervised Learning Based Definition of Microbial Rare Biosphere","text":"basic example shows use ulrb divide phylogenetic units three classifications (rare, undetermined abundant): ulrb, can also format original species table, get automatic number clusters plot results:","code":"library(ulrb) ## basic example define_rb(nice_tidy) #> Joining with `by = join_by(Sample, Level)` #> # A tibble: 2,177 × 17 #> # Groups:   Sample, Classification [27] #>    Sample    Classification OTU   Domain Phylum Class Order Family Genus Species #>    <chr>     <fct>          <chr> <chr>  <chr>  <chr> <chr> <chr>  <chr> <chr>   #>  1 ERR20446… Rare           OTU_2 sk__A… p__Eu… c__C… <NA>  <NA>   <NA>  <NA>    #>  2 ERR20446… Rare           OTU_5 sk__A… p__Eu… c__T… <NA>  <NA>   <NA>  <NA>    #>  3 ERR20446… Rare           OTU_6 sk__A… p__Th… <NA>  <NA>  <NA>   <NA>  <NA>    #>  4 ERR20446… Rare           OTU_7 sk__A… p__Th… c__   o__   f__    g__C… <NA>    #>  5 ERR20446… Rare           OTU_8 sk__A… p__Th… c__   o__N… <NA>   <NA>  <NA>    #>  6 ERR20446… Rare           OTU_… sk__A… p__Th… c__   o__N… f__Ni… g__N… <NA>    #>  7 ERR20446… Rare           OTU_… sk__B… p__Ac… <NA>  <NA>  <NA>   <NA>  <NA>    #>  8 ERR20446… Rare           OTU_… sk__B… p__Ac… c__A… o__A… <NA>   <NA>  <NA>    #>  9 ERR20446… Rare           OTU_… sk__B… p__Ac… <NA>  <NA>  <NA>   <NA>  <NA>    #> 10 ERR20446… Rare           OTU_… sk__B… p__Ac… c__A… <NA>  <NA>   <NA>  <NA>    #> # ℹ 2,167 more rows #> # ℹ 7 more variables: Abundance <int>, pam_object <list>, Level <fct>, #> #   Silhouette_scores <dbl>, Cluster_median_abundance <dbl>, #> #   median_Silhouette <dbl>, Evaluation <chr> # nice is an OTU table in wide format head(nice) #>   ERR2044662 ERR2044663 ERR2044664 ERR2044665 ERR2044666 ERR2044667 ERR2044668 #> 1        165        323         51         70        134        216          0 #> 2          0          0          1          0          0          1          0 #> 3          0          0          1          2          2          6          0 #> 4        541       1018        351        115        241       1633        177 #> 5          8          5         41         15         14        146          0 #> 6         15         31        590        133        174       1814         12 #>   ERR2044669 ERR2044670   OTU      Domain            Phylum #> 1         11          0 OTU_2 sk__Archaea  p__Euryarchaeota #> 2          0          0 OTU_3 sk__Archaea  p__Euryarchaeota #> 3          0          0 OTU_4 sk__Archaea  p__Euryarchaeota #> 4       1371          7 OTU_5 sk__Archaea  p__Euryarchaeota #> 5         14          0 OTU_6 sk__Archaea p__Thaumarchaeota #> 6        173          2 OTU_7 sk__Archaea p__Thaumarchaeota #>                       Class                       Order Family #> 1 c__Candidatus_Poseidoniia                        <NA>   <NA> #> 2 c__Candidatus_Poseidoniia o__Candidatus_Poseidoniales    f__ #> 3           c__Halobacteria          o__Halobacteriales   <NA> #> 4         c__Thermoplasmata                        <NA>   <NA> #> 5                      <NA>                        <NA>   <NA> #> 6                       c__                         o__    f__ #>                            Genus                                        Species #> 1                           <NA>                                           <NA> #> 2                            g__ s__Marine_group_II_euryarchaeote_REDSEA-S03_B6 #> 3                           <NA>                                           <NA> #> 4                           <NA>                                           <NA> #> 5                           <NA>                                           <NA> #> 6 g__Candidatus_Nitrosopelagicus                                           <NA> # first, we tidy the \"nice\" OTU table sample_names <- c(\"ERR2044662\", \"ERR2044663\", \"ERR2044664\",                    \"ERR2044665\", \"ERR2044666\", \"ERR2044667\",                    \"ERR2044668\", \"ERR2044669\", \"ERR2044670\")  # If data is in wide format, with samples in cols nice_tidy <- prepare_tidy_data(nice,                                sample_names = sample_names,                                samples_in = \"cols\")  # second, we apply ulrb algorithm in automatic setting nice_classification_results <- define_rb(nice_tidy) #> Joining with `by = join_by(Sample, Level)` # third, we plot microbial community and the quality of k-medoids clustering plot_ulrb(nice_classification_results, taxa_col = \"OTU\", plot_all = TRUE) #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`). #> Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`). # In case you want to inspect the result of a particular sample, do: plot_ulrb(nice_classification_results, taxa_col = \"OTU\", sample_id = \"ERR2044662\")"},{"path":"https://pascoalf.github.io/ulrb/reference/check_CH.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Calinski-Harabasz index — check_CH","title":"Check Calinski-Harabasz index — check_CH","text":"Calculates Calinski-Harabasz pseudo F-statistic (CH) given sample","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/check_CH.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Calinski-Harabasz index — check_CH","text":"","code":"check_CH(   data,   sample_id,   samples_col = \"Sample\",   abundance_col = \"Abundance\",   range = 3:10,   with_plot = FALSE,   ... )"},{"path":"https://pascoalf.github.io/ulrb/reference/check_CH.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Calinski-Harabasz index — check_CH","text":"data tibble , least, column Abundance Sample. Additional columns allowed. sample_id String name sample apply function. samples_col String name column sample names. abundance_col String name column abundance values. range range values k test, default 3 10. with_plot FALSE (default) returns vector, TRUE return plot scores. ... Extra arguments.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/check_CH.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Calinski-Harabasz index — check_CH","text":"Vector plot Calinski-Harabasz index pre-specified k.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/check_CH.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check Calinski-Harabasz index — check_CH","text":"CH index used decide number clusters clustering algorithm. function, check_CH(), calculates CH index every k pre-specified range values. Thus providing score number clusters tested (k). default range cluster values (k) range = 3:10 (see Pascoal et al., 2024, peer review). However, function may calculate CH index possible k's. Note CH index absolute value indicates quality single clustering. Instead, allows comparison clustering results. Thus, several clusterings, best one one higher CH index. Data input function takes data.frame column samples column abundance (minimum), can take number columns. filter specific sample want analyze. can also pre-filter specific sample, still need provide sample ID (sample_id) table always needs column Sample another Abundance (indicate name arguments samples_col abundance_col). Output options default option returns vector CH scores k. simple output can used analysis. However, also provide option show plot (set with_plot = TRUE) CH score k. Explanation Calinski-Harabasz index CH index variance ratio criterion, measures separation density clusters. higher, better, means points within cluster close ; different clusters well separated. can see CH index : $$CH = \\frac{\\text{inter cluster dispersion}}{\\text{intra cluster dispersion}}$$ calculate inter-cluster: Let \\(k\\) number clusters BGSS -group sum squares, inter-cluster dispersion $$\\frac{BGSS}{(k-1)}$$ calculate BGSS: Let \\(n_k\\) number observations cluster, \\(C\\) centroid dataset (barycenter) \\(C_k\\) centroid cluster, $$BGSS = \\sum_{k = 1}^{k}{n_k * \\left\\lvert C_k-C \\right\\rvert^2}$$ Thus, BGSS multiplies distance cluster centroid centroid whole dataset, observations given cluster, clusters. calculate intra-cluster dispersion: Let \\(WGSS\\) Within Group Sum Squares \\(N\\) total number observations dataset. intra-cluster dispersion $$\\frac{WGSS}{(N-1)}$$ Let \\(X_ik\\) 'th observation cluster \\(n_k\\) number observations cluster. $$WGSS = \\sum_{k=1}^{k}\\sum_{=1}^{n_k}\\left\\lvert X_ik - C_k \\right\\rvert$$ Thus, WGSS measures distance observations cluster center; divided total number observations, gives sense intra-dispersion. Finally, CH index can given : $$CH = \\frac{\\sum_{k = 1}^{k}{n_k * \\left\\lvert C_k-C \\right\\rvert^2}}  {\\sum_{k=1}^{k}\\sum_{=1}^{n_k}\\left\\lvert X_ik - C_k \\right\\rvert}  \\frac{(N-k)}{(k-1)}$$","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/check_CH.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Check Calinski-Harabasz index — check_CH","text":"Calinski, T., & Harabasz, J. (1974). dendrite method cluster analysis. Communications Statistics - Theory Methods, 3(1), 1–27. Pascoal et al., 2024 (peer review)","code":""},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/reference/check_CH.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check Calinski-Harabasz index — check_CH","text":"","code":"library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union # Just scores check_CH(nice_tidy, sample_id = \"ERR2044662\") #> [1]  1821.426  2054.887  4933.956  5465.134 17589.032 17179.809 18083.313 #> [8] 30332.345  # To change range check_CH(nice_tidy, sample_id = \"ERR2044662\", range = 4:11) #> [1]  2054.887  4933.956  5465.134 17589.032 17179.809 18083.313 30332.345 #> [8] 55354.240  # To see a simple plot check_CH(nice_tidy, sample_id = \"ERR2044662\", range = 4:11, with_plot=TRUE)"},{"path":"https://pascoalf.github.io/ulrb/reference/check_DB.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Davies-Bouldin Index — check_DB","title":"Check Davies-Bouldin Index — check_DB","text":"Calculates Davies-Bouldin (DB)Index given sample.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/check_DB.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Davies-Bouldin Index — check_DB","text":"","code":"check_DB(   data,   sample_id,   samples_col = \"Sample\",   abundance_col = \"Abundance\",   range = 3:10,   with_plot = FALSE,   ... )"},{"path":"https://pascoalf.github.io/ulrb/reference/check_DB.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Davies-Bouldin Index — check_DB","text":"data tibble , least, column Abundance Sample. Additional columns allowed. sample_id String name sample apply function. samples_col String name column sample names. abundance_col String name column abundance values. range range values k test, default 3 10. with_plot FALSE (default) returns vector, TRUE return plot scores. ... Extra arguments.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/check_DB.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Davies-Bouldin Index — check_DB","text":"vector plot Davies-Bouldin index pre-specified k given sample.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/check_DB.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check Davies-Bouldin Index — check_DB","text":"DB index used decide number clusters clustering algorithm. function, check_DB(), calculates DB index every k pre-specified range values. Thus providing score number clusters tested (k). default range cluster values (k) range = 3:10 (see Pascoal et al., 2023). However, function may calculate DB index possible k's. Note DB index absolute value indicates quality single clustering. Instead, allows comparison clustering results. Thus, several clusterings, best one one higher DB index. Data input function takes data.frame column samples column abundance (minimum), can take number columns. filter specific sample want analyze. can also pre-filter specific sample, still need provide sample ID (sample_id) table always needs column Sample another Abundance (indicate name arguments samples_col abundance_col). Output options default option returns vector DB scores k. simple output can used analysis. However, also provide option show plot (set with_plot = TRUE) DB score k. Explanation Davies-Bouldin index DB index (Davies Bouldin, 1979) averaged measure cluster similarity closest cluster. provides sense separated clusters . Lower DB scores better, represent distinct clusters. Higher values DB indicate overlapping clusters. Let \\(N\\) number clusters \\(R_i\\) similarity 'th cluster cluster similar . DB index calculated mean similarity cluster similar cluster, $$DB = \\frac{1}{N}\\sum_{=1}^{N}R_i$$ Thus, \\(R_i\\) maximum similarity among possible combinations \\(R_{ij}\\), \\(\\neq j\\). get \\(R_ij\\), let \\(S_i\\) intra-cluster dispersion \\(\\), \\(S_j\\) intra-cluster dispersion cluster \\(j\\) \\(M_ij\\) distance clusters \\(\\) \\(j\\). similarity two clusters, \\(\\) \\(j\\), : $$ R_{ij} = \\frac{S_i + S_j}{M_ij}$$ distance two clusters, \\(M_ij\\), measured distance centroids clusters, \\(\\left\\lvert C_i - C_j \\right\\rvert\\). dispersion clusters, \\(S_i\\), provides sense intra-dispersion given cluster. calculate \\(S_i\\), let \\(T_i\\) \\(T_j\\) number observations \\(\\) \\(j\\), respectively; let \\(X_j\\) value j'th observation (, \\(\\neq j\\)). $$S_i = \\sqrt{\\frac{1}{T_i}\\sum_{j=1}^{T_i}\\left\\lvert X_j - C_i \\right\\rvert}$$ Note case euclidean distances.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/check_DB.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Check Davies-Bouldin Index — check_DB","text":"Davies, D. L., & Bouldin, D. W. (1979). Cluster Separation Measure. IEEE Transactions Pattern Analysis Machine Intelligence, PAMI-1(2).","code":""},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/reference/check_DB.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check Davies-Bouldin Index — check_DB","text":"","code":"library(dplyr) # Just scores check_DB(nice_tidy, sample_id = \"ERR2044662\") #> [1] 0.3721866 0.5271704 0.4131651 0.4292696 0.3350836 0.3892966 0.3948026 #> [8] 0.3294451  # To change range check_DB(nice_tidy, sample_id = \"ERR2044662\", range = 4:11) #> [1] 0.5271704 0.4131651 0.4292696 0.3350836 0.3892966 0.3948026 0.3294451 #> [8] 0.2782100  # To see a simple plot check_DB(nice_tidy, sample_id = \"ERR2044662\", range = 4:11, with_plot=TRUE)"},{"path":"https://pascoalf.github.io/ulrb/reference/check_avgSil.html","id":null,"dir":"Reference","previous_headings":"","what":"Check average Silhouette score index — check_avgSil","title":"Check average Silhouette score index — check_avgSil","text":"Calculates average Silhouette score given sample.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/check_avgSil.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check average Silhouette score index — check_avgSil","text":"","code":"check_avgSil(   data,   sample_id = NULL,   samples_col = \"Sample\",   abundance_col = \"Abundance\",   range = 3:10,   with_plot = FALSE,   ... )"},{"path":"https://pascoalf.github.io/ulrb/reference/check_avgSil.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check average Silhouette score index — check_avgSil","text":"data tibble , least, column Abundance Sample. Additional columns allowed. sample_id String name sample apply function. samples_col String name column sample names. abundance_col String name column abundance values. range range values k test, default 3 10. with_plot FALSE (default) returns vector, TRUE return plot scores. ... Extra arguments.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/check_avgSil.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check average Silhouette score index — check_avgSil","text":"Vector average Silhouette score index pre-specified k.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/check_avgSil.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check average Silhouette score index — check_avgSil","text":"average Silhouette score index provides sense cluster definition separation. varies -1 (complete cluster overlap) 1 (cluster overlap), closest 1, better. Thus, k value highest average Silhouette score best k. standard metric used ulrb package automation decision k, functions suggest_k() define_rb(). Note: average Silhouette score different common calculation Silhouette index, provides score observation clustering result. Just like name says, taking average silhouette scores obtained clustering result. way can single, comparable value k test. Data input function takes data.frame column samples column abundance (minimum), can take number columns. filter specific sample want analyze. can also pre-filter specific sample, still need provide sample ID (sample_id) table always needs column Sample another Abundance (indicate name arguments samples_col abundance_col). Output options default option returns vector CH scores k. simple output can used analysis. However, also provide option show plot (set with_plot = TRUE) CH score k. Note function plot classical Silhouette plot clustering result. particular plot, use function plot_ulrb_silhouette() instead. Explanation average Silhouette score calculate Silhouette score single observation, let: \\(\\) mean distance observation observations cluster; \\(b\\) mean distance observations cluster centroid nearest cluster. silhouette score (Sil), given : $$Sil = \\frac{(b-)}{max(,b)}$$ Silhouette score observations clustering result, just take simple mean get average Silhouette score. Silhouette score intuition formula, \\(Sil = \\frac{(b-)}{max(,b)}\\), clear , given observation: \\(> b\\), Silhouette score approaches 1; means distance observation cluster larger distance nearest different cluster. distance must maximized points cluster similar , clusters. \\(= b\\), Silhouette score 0; means distance observation cluster equivalent distance nearest different cluster. \\(< b\\), Silhouette score approaches -1; situation, observation nearer nearest different cluster, cluster. Thus, negative score indicates observation correct cluster. average Silhouette score intuition take average Silhouette score obtained observation clustering result, ability compare overall success clustering another clustering. Thus, compare average Silhouette score across different k values, .e. different number clusters, can select k highest average Silhouette score.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/check_avgSil.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Check average Silhouette score index — check_avgSil","text":"Rousseeuw, P. J. (1987). Silhouettes: graphical aid interpretation validation cluster analysis. Journal Computational Applied Mathematics, 20(C), 53–65.","code":""},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/reference/check_avgSil.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check average Silhouette score index — check_avgSil","text":"","code":"library(dplyr) # Just scores check_avgSil(nice_tidy, sample_id = \"ERR2044662\") #> [1] 0.9521452 0.8820316 0.8561774 0.8398216 0.8479872 0.7843358 0.7740169 #> [8] 0.7701163  # To change range check_avgSil(nice_tidy, sample_id = \"ERR2044662\", range = 4:11) #> [1] 0.8820316 0.8561774 0.8398216 0.8479872 0.7843358 0.7740169 0.7701163 #> [8] 0.7629755  # To see a simple plot check_avgSil(nice_tidy, sample_id = \"ERR2044662\", range = 4:11, with_plot=TRUE)"},{"path":"https://pascoalf.github.io/ulrb/reference/define_rb.html","id":null,"dir":"Reference","previous_headings":"","what":"Define Rare Biosphere — define_rb","title":"Define Rare Biosphere — define_rb","text":"Classifies species sample either \"Rare\", \"Undetermined\" \"Abundant\". classifications allowed.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/define_rb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define Rare Biosphere — define_rb","text":"","code":"define_rb(   data,   classification_vector = c(\"Rare\", \"Undetermined\", \"Abundant\"),   samples_col = \"Sample\",   abundance_col = \"Abundance\",   simplified = FALSE,   automatic = FALSE,   index = \"Average Silhouette Score\",   ... )"},{"path":"https://pascoalf.github.io/ulrb/reference/define_rb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define Rare Biosphere — define_rb","text":"data tibble , least, column Abundance Sample. Additional columns allowed. classification_vector vector strings names cluster, lower higher abundance. Default c(\"Rare\", \"Undetermined\", \"Abundance\"). samples_col String name column sample names. abundance_col String name column abundance values. simplified Can TRUE/FALSE. Default (FALSE) provides additional column detailed pam() results Silhouette scores. TRUE, Classification result added original input data. automatic default (FALSE), assume classification \"Rare\", \"Undetermined\" \"Abundant\". TRUE, automatically select number classifications (k), based index argument. index Index used select best k. Can one : \"Average Silhouette Score\", \"Davies-Bouldin\" \"Calinski-Harabasz\". ... Extra arguments.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/define_rb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define Rare Biosphere — define_rb","text":"input data.frame extra columns containing classification additional metrics (detailed = TRUE).","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/define_rb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define Rare Biosphere — define_rb","text":"Overview Function cluster species abundance partition around medoids algorithm (Kaufman Rousseuw. 1991). default, propose division three clusters (k = 3), can convenient description : \"rare\", \"undetermined\" \"abundant\". phylogenetic units cluster lowest median abundance considered \"rare biosphere\". classification vector classification vector (argument classification_vector) represents different clusters used, ascending order median abundance. change number clusters, change number elements classification vector, order matters! Depending number clusters used, can change meaning best applies research. example, can use classification vector designations: \"rare\", \"rare\", \"abundant\" \"abundant\"; apply k = 4 underneath. possible use number clusters, long within 2 maximum possible k. maximum possible k number different abundance scores observed single sample. Note, however, recommend clustering k > 10 also recommend k = 2 (explain detail Pascoal et al., 2023; vignette vignette(\"explore-classifications\"). Automatic selection number clusters automatically decide number clusters (.e., value k), possible argument automatic=TRUE. details complete automation define_rb(), please see documentation suggest_k(). Briefly, k best average Silhouette score selected range k values 3 10. possible decide k based indices (\"Davies-Bouldin\" \"Calinsky-Harabasz\"). want fine grained analysis k values, provide several functions: evaluate_k(); check_avgSil(); check_DB(); check_CH(). Verify clustering results half taxa cluster got Silhouette score 0.5 sample, warning provided. warning provides number times issue occurred. can inspect alternatives reduce occurrences bad clustering, possible , situations, just find optimal clustering. detailed output gives access clustering results: pam_object list original results k-medoids clustering, see cluster::pam() documentation. Level integer indicating specific cluster attributed cluster::pam() function observation. order random. Silhouette_scores provides Silhouette score obtained observation, .e. score taxa. Cluster_median_abundance provides median taxa abundance cluster. median_Silhouette provides median Silhouette score obtained cluster. Evaluation indicates silhouette score obtained given observation median Silhouette cluster sample. can make plots analysis, also provide another function, plot_ulrb(), illustrates results obtained. Partition around medoids (pam) calculate k-medoids, used partition around medoids (pam) algorithm, described Chapter 2 \"Finding Groups Data: Introduction Cluster Analysis.\" (Kaufman Rousseeuw, 1991) implemented cluster package cluster::pam() function. Briefly, pam algorithm divided two main phases: build swap. first phase (build) selects k observations cluster representatives. first observation selected representative one minimizes sum dissimilarities remaining observations. second, third repeat process, k clusters formed. build steps : 1 - Propose centroid observation, \\(\\), selected centroid yet 2 - Calculate distance another observation, \\(j\\), similar observation, \\(D_j\\); calculate difference proposed centroid, \\(\\), .e., \\(d(j,)\\) 3 - \\(d(j,) > 0\\), calculate contribution centroid: $$max(D_j - d(j,),0)$$ 4 - Calculate total gain obtained \\(\\), $$\\sum_{j}C_{ji}$$ 5 - possible centroids, select one maximizes previous total gain obtained, $$max_i \\sum_jC_{ji}$$ 6 - Repeat k observations selected cluster representatives. purpose next phase, swap, improve representatives clusters. principle swap cluster representative possibilities calculate value sum dissimilarities observation closest centroid. swapping continues improvement possible, .e., minimum sum dissimilarities clusters reached. Notes: Understand ulrb package considers sample independent community phylogenetic units, means clustering also independent across different samples. Thus, aware clustering results metrics single sample, also provide functions analyze results across number samples (see: plot_ulrb() clustering results evaluate_k() k selection).","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/define_rb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Define Rare Biosphere — define_rb","text":"Kaufman, L., & Rousseuw, P. J. (1991). Chapter 2 book Finding Groups Data: Introduction Cluster Analysis. Biometrics, 47(2), 788.","code":""},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/reference/define_rb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define Rare Biosphere — define_rb","text":"","code":"# \\donttest{ library(dplyr) # Sample ID's sample_names <- c(\"ERR2044662\", \"ERR2044663\", \"ERR2044664\",                    \"ERR2044665\", \"ERR2044666\", \"ERR2044667\",                    \"ERR2044668\", \"ERR2044669\", \"ERR2044670\")  # If data is in wide format, with samples in cols nice_tidy <- prepare_tidy_data(nice,                                sample_names = sample_names,                                samples_in = \"cols\")  # Straightforward with tidy format define_rb(nice_tidy) #> Joining with `by = join_by(Sample, Level)` #> # A tibble: 2,177 × 17 #> # Groups:   Sample, Classification [27] #>    Sample    Classification OTU   Domain Phylum Class Order Family Genus Species #>    <chr>     <fct>          <chr> <chr>  <chr>  <chr> <chr> <chr>  <chr> <chr>   #>  1 ERR20446… Rare           OTU_2 sk__A… p__Eu… c__C… NA    NA     NA    NA      #>  2 ERR20446… Rare           OTU_5 sk__A… p__Eu… c__T… NA    NA     NA    NA      #>  3 ERR20446… Rare           OTU_6 sk__A… p__Th… NA    NA    NA     NA    NA      #>  4 ERR20446… Rare           OTU_7 sk__A… p__Th… c__   o__   f__    g__C… NA      #>  5 ERR20446… Rare           OTU_8 sk__A… p__Th… c__   o__N… NA     NA    NA      #>  6 ERR20446… Rare           OTU_… sk__A… p__Th… c__   o__N… f__Ni… g__N… NA      #>  7 ERR20446… Rare           OTU_… sk__B… p__Ac… NA    NA    NA     NA    NA      #>  8 ERR20446… Rare           OTU_… sk__B… p__Ac… c__A… o__A… NA     NA    NA      #>  9 ERR20446… Rare           OTU_… sk__B… p__Ac… NA    NA    NA     NA    NA      #> 10 ERR20446… Rare           OTU_… sk__B… p__Ac… c__A… NA    NA     NA    NA      #> # ℹ 2,167 more rows #> # ℹ 7 more variables: Abundance <int>, pam_object <list>, Level <fct>, #> #   Silhouette_scores <dbl>, Cluster_median_abundance <dbl>, #> #   median_Silhouette <dbl>, Evaluation <chr>  #Closer look classified_table <- define_rb(nice_tidy) #> Joining with `by = join_by(Sample, Level)` classified_table %>% select(Sample, Abundance, Classification) %>% head() #> # A tibble: 6 × 3 #> # Groups:   Sample, Classification [1] #>   Sample     Abundance Classification #>   <chr>          <int> <fct>          #> 1 ERR2044662       165 Rare           #> 2 ERR2044662       541 Rare           #> 3 ERR2044662         8 Rare           #> 4 ERR2044662        15 Rare           #> 5 ERR2044662         5 Rare           #> 6 ERR2044662         4 Rare             # Automatic decision, instead of a predefined definition define_rb(nice_tidy, automatic = TRUE) %>% select(Sample, Abundance, Classification) #> Automatic option set to TRUE, so classification vector was overwritten #> K= 3 based on Average Silhouette Score. #> Joining with `by = join_by(Sample, Level)` #> # A tibble: 2,177 × 3 #> # Groups:   Sample, Classification [27] #>    Sample     Abundance Classification #>    <chr>          <int> <fct>          #>  1 ERR2044662       165 1              #>  2 ERR2044662       541 1              #>  3 ERR2044662         8 1              #>  4 ERR2044662        15 1              #>  5 ERR2044662         5 1              #>  6 ERR2044662         4 1              #>  7 ERR2044662        19 1              #>  8 ERR2044662         1 1              #>  9 ERR2044662        61 1              #> 10 ERR2044662       123 1              #> # ℹ 2,167 more rows  # Automatic decision, using Davies-Bouldin index, # instead of average Silhouette score (default) define_rb(nice_tidy, automatic = TRUE, index = \"Davies-Bouldin\") %>% select(Sample, Abundance, Classification) #> Automatic option set to TRUE, so classification vector was overwritten #> K= 6 based on Davies-Bouldin. #> Joining with `by = join_by(Sample, Level)` #> Warning: 1 samples got a bad Silhouette score. Consider changing the number of classifications. #> If half the observations within a classification are below 0.5 Silhouette score, we consider that the clustering was 'Bad'. #> Check 'Evaluation' collumn for more details. #> # A tibble: 2,177 × 3 #> # Groups:   Sample, Classification [54] #>    Sample     Abundance Classification #>    <chr>          <int> <fct>          #>  1 ERR2044662       165 2              #>  2 ERR2044662       541 2              #>  3 ERR2044662       190 2              #>  4 ERR2044662       374 2              #>  5 ERR2044662       308 2              #>  6 ERR2044662       261 2              #>  7 ERR2044662       196 2              #>  8 ERR2044662       576 2              #>  9 ERR2044662       264 2              #> 10 ERR2044662       308 2              #> # ℹ 2,167 more rows  # User defined classifications user_classifications <- c(\"very rare\",                           \"rare\",                           \"undetermined\",                           \"abundant\",                           \"very abundant\")  define_rb(nice_tidy, classification_vector = user_classifications) %>% select(Sample, Abundance, Classification) #> Joining with `by = join_by(Sample, Level)` #> # A tibble: 2,177 × 3 #> # Groups:   Sample, Classification [45] #>    Sample     Abundance Classification #>    <chr>          <int> <fct>          #>  1 ERR2044662       165 very rare      #>  2 ERR2044662         8 very rare      #>  3 ERR2044662        15 very rare      #>  4 ERR2044662         5 very rare      #>  5 ERR2044662         4 very rare      #>  6 ERR2044662        19 very rare      #>  7 ERR2044662         1 very rare      #>  8 ERR2044662        61 very rare      #>  9 ERR2044662       123 very rare      #> 10 ERR2044662         1 very rare      #> # ℹ 2,167 more rows  # Easy to incorporate in big pipes # Remove Archaea # Remove taxa below 10 reads # Classify according to a different set of classifications nice_tidy %>%  filter(Domain != \"sk__Archaea\") %>%  filter(Abundance > 10) %>%  define_rb(classification_vector = c(\"very rare\",                                      \"rare\",                                      \"abundant\",                                      \"very abundant\")) %>%  select(Sample, Abundance, Classification) #> Joining with `by = join_by(Sample, Level)` #> # A tibble: 885 × 3 #> # Groups:   Sample, Classification [36] #>    Sample     Abundance Classification #>    <chr>          <int> <fct>          #>  1 ERR2044662        19 very rare      #>  2 ERR2044662        61 very rare      #>  3 ERR2044662       123 very rare      #>  4 ERR2044662        75 very rare      #>  5 ERR2044662        24 very rare      #>  6 ERR2044662       190 very rare      #>  7 ERR2044662        13 very rare      #>  8 ERR2044662        23 very rare      #>  9 ERR2044662        20 very rare      #> 10 ERR2044662       374 very rare      #> # ℹ 875 more rows   # An example that summarises results nice_tidy %>%  filter(Domain != \"sk__Archaea\") %>%  filter(Abundance > 10) %>%  define_rb(classification_vector = c(\"very rare\",                                      \"rare\",                                      \"abundant\",                                      \"very abundant\")) %>%  select(Sample, Abundance, Classification) %>%  group_by(Sample, Classification) %>%  summarise(totalAbundance = sum(Abundance)) #> Joining with `by = join_by(Sample, Level)` #> `summarise()` has grouped output by 'Sample'. You can override using the #> `.groups` argument. #> # A tibble: 36 × 3 #> # Groups:   Sample [9] #>    Sample     Classification totalAbundance #>    <chr>      <fct>                   <int> #>  1 ERR2044662 very rare                5842 #>  2 ERR2044662 rare                     8632 #>  3 ERR2044662 abundant                12953 #>  4 ERR2044662 very abundant           24242 #>  5 ERR2044663 very rare                9555 #>  6 ERR2044663 rare                    12622 #>  7 ERR2044663 abundant                14846 #>  8 ERR2044663 very abundant           28412 #>  9 ERR2044664 very rare                3143 #> 10 ERR2044664 rare                     6306 #> # ℹ 26 more rows # }"},{"path":"https://pascoalf.github.io/ulrb/reference/evaluate_k.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate k from all samples in a dataset — evaluate_k","title":"Evaluate k from all samples in a dataset — evaluate_k","text":"function extends evaluate_sample_k() number samples dataset.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/evaluate_k.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate k from all samples in a dataset — evaluate_k","text":"","code":"evaluate_k(   data,   range = 3:10,   samples_col = \"Sample\",   abundance_col = \"Abundance\",   with_plot = FALSE,   ... )"},{"path":"https://pascoalf.github.io/ulrb/reference/evaluate_k.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate k from all samples in a dataset — evaluate_k","text":"data data.frame , least, classification, abundance sample information phylogenetic unit. range range values k test, default 3 10. samples_col String name column sample names. abundance_col string name column abundance values. Default \"Abundance\". with_plot FALSE (default) returns vector, TRUE return plot scores. ... Extra arguments.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/evaluate_k.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate k from all samples in a dataset — evaluate_k","text":"nested data.frame (plot) three indices k sample.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/evaluate_k.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate k from all samples in a dataset — evaluate_k","text":"plot option (with_plot = TRUE) provides centrality metrics samples used. details indices calculation, please see documentation evaluate_sample_k(), check_DB(), check_CH() check_avgSil().","code":""},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/reference/evaluate_k.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate k from all samples in a dataset — evaluate_k","text":"","code":"# \\donttest{ library(dplyr)  #' evaluate_k(nice_tidy)   # To make simple plot evaluate_k(nice_tidy, range = 4:11, with_plot =TRUE) #> No summary function supplied, defaulting to `mean_se()` #> No summary function supplied, defaulting to `mean_se()` #> No summary function supplied, defaulting to `mean_se()`  # }"},{"path":"https://pascoalf.github.io/ulrb/reference/evaluate_sample_k.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate sample k — evaluate_sample_k","title":"Evaluate sample k — evaluate_sample_k","text":"functions calculates three indices (Davies-Bouldin, Calinsky-Harabasz average Silhouette score) k. Calculations made single sample default range k goes 3 10.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/evaluate_sample_k.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate sample k — evaluate_sample_k","text":"","code":"evaluate_sample_k(   data,   sample_id,   samples_col = \"Sample\",   abundance_col = \"Abundance\",   range = 3:10,   with_plot = FALSE,   ... )"},{"path":"https://pascoalf.github.io/ulrb/reference/evaluate_sample_k.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate sample k — evaluate_sample_k","text":"data data.frame , least, classification, abundance sample information phylogenetic unit. sample_id String name sample apply function. samples_col String name column sample names. abundance_col string name column abundance values. Default \"Abundance\". range range values k test, default 3 10. with_plot FALSE (default) returns vector, TRUE return plot scores. ... Extra arguments.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/evaluate_sample_k.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate sample k — evaluate_sample_k","text":"data.frame (plot) several indices number clusters.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/evaluate_sample_k.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate sample k — evaluate_sample_k","text":"Note: get indices samples, use evaluate_k() instead. Data input function takes data.frame column samples column abundance (minimum), can take number columns. filter specific sample want analyze. can also pre-filter specific sample, still need provide sample ID (sample_id) table always needs column Sample another Abundance (indicate name arguments samples_col abundance_col). Output options default option returns data.frame Davies-Bouldin, Calinsky-Harabasz average Silhouette scores k. simple output can used analysis. However, also provide option show plot (set with_plot = TRUE). Three indices calculated function: Davies-Bouldin check_DB(); Calinsky-Harabasz check_DB(); average Silhouette score check_avgSil().","code":""},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/reference/evaluate_sample_k.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate sample k — evaluate_sample_k","text":"","code":"library(dplyr) # evaluate_sample_k(nice_tidy, sample_id = \"ERR2044662\") #>          DB        CH average_Silhouette  k #> 1 0.3721866  1821.426          0.9521452  3 #> 2 0.5271704  2054.887          0.8820316  4 #> 3 0.4131651  4933.956          0.8561774  5 #> 4 0.4292696  5465.134          0.8398216  6 #> 5 0.3350836 17589.032          0.8479872  7 #> 6 0.3892966 17179.809          0.7843358  8 #> 7 0.3948026 18083.313          0.7740169  9 #> 8 0.3294451 30332.345          0.7701163 10  # To change range evaluate_sample_k(nice_tidy, sample_id = \"ERR2044662\", range = 4:11) #>          DB        CH average_Silhouette  k #> 1 0.5271704  2054.887          0.8820316  4 #> 2 0.4131651  4933.956          0.8561774  5 #> 3 0.4292696  5465.134          0.8398216  6 #> 4 0.3350836 17589.032          0.8479872  7 #> 5 0.3892966 17179.809          0.7843358  8 #> 6 0.3948026 18083.313          0.7740169  9 #> 7 0.3294451 30332.345          0.7701163 10 #> 8 0.2782100 55354.240          0.7629755 11  # To make simple plot evaluate_sample_k(nice_tidy, sample_id = \"ERR2044662\", range = 4:11, with_plot =TRUE)"},{"path":"https://pascoalf.github.io/ulrb/reference/nice.html","id":null,"dir":"Reference","previous_headings":"","what":"V4-V5 16S rRNA gene amplicons, clean OTU table (N-ICE, 2015) — nice","title":"V4-V5 16S rRNA gene amplicons, clean OTU table (N-ICE, 2015) — nice","text":"Table \"wide\" format abundance taxonomic classification OTU.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/nice.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"V4-V5 16S rRNA gene amplicons, clean OTU table (N-ICE, 2015) — nice","text":"","code":"nice"},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/reference/nice.html","id":"nice","dir":"Reference","previous_headings":"","what":"nice","title":"V4-V5 16S rRNA gene amplicons, clean OTU table (N-ICE, 2015) — nice","text":"data frame 524 rows 17 columns: ERR2044662, ERR2044663, ERR2044664, ERR2044665, ERR2044666, ERR2044667, ERR2044668, ERR2044669 ERR2044670 Sample ID OTU OTU ID Domain Domain level classification OTU Phylum Phylum level classification OTU Class Class level classification OTU Order Order level classification OTU Family Family level classification OTU Genus Genus level classification OTU Species Species level classification OTU","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/nice.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"V4-V5 16S rRNA gene amplicons, clean OTU table (N-ICE, 2015) — nice","text":"https://www.ebi.ac.uk/metagenomics/studies/MGYS00001922#analysis","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/nice.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"V4-V5 16S rRNA gene amplicons, clean OTU table (N-ICE, 2015) — nice","text":"OTU table cleaned includes samples 16S rRNA amplicon sequencing eukaryotes (similarly Pascoal et al., 2022). Additionally, added column ID OTU. details raw data, see nice_raw","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/nice.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"V4-V5 16S rRNA gene amplicons, clean OTU table (N-ICE, 2015) — nice","text":"Pascoal, F., Costa, R., Assmy, P., Duarte, P., & Magalhães, C. (2022). Exploration Types Rarity Arctic Ocean Perspective Multiple Methodologies. Microbial Ecology, 84(1), 59–72. https://doi.org/10.1007/s00248-021-01821-9","code":""},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/reference/nice_env.html","id":null,"dir":"Reference","previous_headings":"","what":"Metadata of samples from OTU tables (N-ICE, 2015) — nice_env","title":"Metadata of samples from OTU tables (N-ICE, 2015) — nice_env","text":"dataset provides information samples used N-ICE dataset.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/nice_env.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Metadata of samples from OTU tables (N-ICE, 2015) — nice_env","text":"","code":"nice_env"},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/reference/nice_env.html","id":"nice-tidy","dir":"Reference","previous_headings":"","what":"nice_tidy","title":"Metadata of samples from OTU tables (N-ICE, 2015) — nice_env","text":"data frame 4716 rows 10 columns: Sample Sample ID used original study ENA_ID Sample ID equivalent Sample OTU table Month Month sampling Region Ocean region sampling event Water.mass Water mass sampling event Latitude Latitude sampling event Longitude Longitude sampling event","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/nice_env.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Metadata of samples from OTU tables (N-ICE, 2015) — nice_env","text":"https://link.springer.com/article/10.1007/s00248-021-01821-9","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/nice_env.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Metadata of samples from OTU tables (N-ICE, 2015) — nice_env","text":"Based de Sousa et al., 2019.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/nice_env.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Metadata of samples from OTU tables (N-ICE, 2015) — nice_env","text":"de Sousa, . G. G., Tomasino, M. P., Duarte, P., Fernández-Méndez, M., Assmy, P., Ribeiro, H., Surkont, J., Leite, R. B., Pereira-Leal, J. B., Torgo, L., & Magalhães, C. (2019). Diversity Composition Pelagic Prokaryotic Protist Communities Thin Arctic Sea-Ice Regime. Microbial Ecology, 78(2), 388–408.","code":""},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/reference/nice_raw.html","id":null,"dir":"Reference","previous_headings":"","what":"V4-V5 16S rRNA gene amplicons, raw OTU table (N-ICE, 2015) — nice_raw","title":"V4-V5 16S rRNA gene amplicons, raw OTU table (N-ICE, 2015) — nice_raw","text":"\"raw\" data N-ICE dataset.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/nice_raw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"V4-V5 16S rRNA gene amplicons, raw OTU table (N-ICE, 2015) — nice_raw","text":"","code":"nice_raw"},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/reference/nice_raw.html","id":"nice-raw","dir":"Reference","previous_headings":"","what":"nice_raw","title":"V4-V5 16S rRNA gene amplicons, raw OTU table (N-ICE, 2015) — nice_raw","text":"data frame 524 rows 17 columns: ERR2044662, ERR2044663, ERR2044664, ERR2044665, ERR2044666, ERR2044667, ERR2044668, ERR2044669 ERR2044670 Sample ID OTU OTU ID Domain Domain level classification OTU Phylum Phylum level classification OTU Class Class level classification OTU Order Order level classification OTU Family Family level classification OTU Genus Genus level classification OTU Species Species level classification OTU","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/nice_raw.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"V4-V5 16S rRNA gene amplicons, raw OTU table (N-ICE, 2015) — nice_raw","text":"https://www.ebi.ac.uk/metagenomics/studies/MGYS00001922#analysis","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/nice_raw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"V4-V5 16S rRNA gene amplicons, raw OTU table (N-ICE, 2015) — nice_raw","text":"original sequencing results available European Nucleotide Archive (accession number: PRJEB15043). reads processed OTUs MGnify platform (Study: MGYS00001922). later study accession provides table used . table contains taxonomy abundance score taxonomic lineage, refer \"OTU\" (Operational OTU) simplicity sake. details sampling campaign Arctic ocean, sequencing protocols bioinformatic processing, please see ref (de Sousa et al., 2019).","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/nice_raw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"V4-V5 16S rRNA gene amplicons, raw OTU table (N-ICE, 2015) — nice_raw","text":"de Sousa, . G. G., Tomasino, M. P., Duarte, P., Fernández-Méndez, M., Assmy, P., Ribeiro, H., Surkont, J., Leite, R. B., Pereira-Leal, J. B., Torgo, L., & Magalhães, C. (2019). Diversity Composition Pelagic Prokaryotic Protist Communities Thin Arctic Sea-Ice Regime. Microbial Ecology, 78(2), 388–408. https://doi.org/10.1007/s00248-018-01314-2","code":""},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/reference/nice_tidy.html","id":null,"dir":"Reference","previous_headings":"","what":"V4-V5 16S rRNA gene amplicons, clean OTU table in tidy/long format (N-ICE, 2015) — nice_tidy","title":"V4-V5 16S rRNA gene amplicons, clean OTU table in tidy/long format (N-ICE, 2015) — nice_tidy","text":"Original OTU table (nice) \"long\" format.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/nice_tidy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"V4-V5 16S rRNA gene amplicons, clean OTU table in tidy/long format (N-ICE, 2015) — nice_tidy","text":"","code":"nice_tidy"},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/reference/nice_tidy.html","id":"nice-tidy","dir":"Reference","previous_headings":"","what":"nice_tidy","title":"V4-V5 16S rRNA gene amplicons, clean OTU table in tidy/long format (N-ICE, 2015) — nice_tidy","text":"data frame 4716 rows 10 columns: Sample Sample ID Abundance Abundance OTU OTU ID Domain Domain level classification OTU Phylum Domain level classification OTU Class Domain level classification OTU Order Domain level classification OTU Family Domain level classification OTU Genus Domain level classification OTU Species Domain level classification OTU","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/nice_tidy.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"V4-V5 16S rRNA gene amplicons, clean OTU table in tidy/long format (N-ICE, 2015) — nice_tidy","text":"https://www.ebi.ac.uk/metagenomics/studies/MGYS00001922#analysis","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/nice_tidy.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"V4-V5 16S rRNA gene amplicons, clean OTU table in tidy/long format (N-ICE, 2015) — nice_tidy","text":"new column (Sample) includes sample identifiers new column (Abundance) includes abundance OTU. details OTU table processing see help pages nice nice_raw. details N-ICE dataset: dataset resulted Norwegian Young Sea Ice expedition (N-ICE) 2015 (Granskog et al., 2018). sample processing DNA sequencing described de Sousa et al., 2019, bioinformatic processing performed MGnify platform (v5) (Mitchell et al., 2020). Since purpose dataset creating examples testing package, apply strict quality control final OTU table. Thus, remove singletons, etc. However, remove non-prokarotic OTUs organelles, (Pascoal et al., 2022).","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/nice_tidy.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"V4-V5 16S rRNA gene amplicons, clean OTU table in tidy/long format (N-ICE, 2015) — nice_tidy","text":"Mitchell, . L., Almeida, ., Beracochea, M., Boland, M., Burgin, J., Cochrane, G., Crusoe, M. R., Kale, V., Potter, S. C., Richardson, L. J., Sakharova, E., Scheremetjew, M., Korobeynikov, ., Shlemov, ., Kunyavskaya, O., Lapidus, ., & Finn, R. D. (2019). MGnify: microbiome analysis resource 2020. Nucleic Acids Research, 48(D1), D570–D578. Granskog, M. ., Fer, ., Rinke, ., & Steen, H. (2018). Atmosphere-Ice-Ocean-Ecosystem Processes Thinner Arctic Sea Ice Regime: Norwegian Young Sea ICE (N-ICE2015) Expedition. Journal Geophysical Research: Oceans, 123(3), 1586–1594. de Sousa, . G. G., Tomasino, M. P., Duarte, P., Fernández-Méndez, M., Assmy, P., Ribeiro, H., Surkont, J., Leite, R. B., Pereira-Leal, J. B., Torgo, L., & Magalhães, C. (2019). Diversity Composition Pelagic Prokaryotic Protist Communities Thin Arctic Sea-Ice Regime. Microbial Ecology, 78(2), 388–408. Pascoal, F., Costa, R., Assmy, P., Duarte, P., & Magalhães, C. (2022). Exploration Types Rarity Arctic Ocean Perspective Multiple Methodologies. Microbial Ecology, 84(1), 59–72.","code":""},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/reference/plot_ulrb.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot ulrb clustering results and silhouette scores — plot_ulrb","title":"Plot ulrb clustering results and silhouette scores — plot_ulrb","text":"Function help access clustering results ulrb.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/plot_ulrb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot ulrb clustering results and silhouette scores — plot_ulrb","text":"","code":"plot_ulrb(   data,   sample_id = NULL,   taxa_col,   plot_all = FALSE,   silhouette_score = \"Silhouette_scores\",   classification_col = \"Classification\",   abundance_col = \"Abundance\",   log_scaled = FALSE,   colors = c(\"#009E73\", \"#F0E442\", \"#CC79A7\"),   ... )"},{"path":"https://pascoalf.github.io/ulrb/reference/plot_ulrb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot ulrb clustering results and silhouette scores — plot_ulrb","text":"data data.frame , least, classification, abundance sample information phylogenetic unit. sample_id string name selected sample. taxa_col string name column phylogenetic units. Usually OTU ASV. plot_all TRUE, make plot samples mean standard deviation. FALSE (default), plot illustrate single sample, specifiy sample_id argument. silhouette_score string column name silhouette score values. Default \"Silhouette_scores\" classification_col string name column classification row. Default value \"Classification\". abundance_col string name column abundance values. Default \"Abundance\". log_scaled TRUE abundance scores shown Log10 scale. Default FALSE. colors vector colors. lenght number classifications. ... arguments","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/plot_ulrb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot ulrb clustering results and silhouette scores — plot_ulrb","text":"grid ggplot objects clustering results silhouette plot obtained define_rb().","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/plot_ulrb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot ulrb clustering results and silhouette scores — plot_ulrb","text":"function combined plot_ulrb_clustering() plot_ulrb_silhouette(). plots can done single sample samples. results main function ulrb package, define_rb(), include classification species (OTU, ASVs, etc) silhouette score obtained observation. Thus, access clustering results, two main plots check: rank abundance curve obtained ulrb classification; silhouette plot. Interpretation Silhouette plot Based chapter 2 \"Finding Groups Data: Introduction Cluster Analysis.\" (Kaufman Rousseeuw, 1991); possible (subjective) interpretation clustering structure based Silhouette plot : 0.71-1.00 (strong structure found); 0.51-0.70 (reasonable structure found); 0.26-0.50 (structure weak artificial); <0.26 (structure found).","code":""},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/reference/plot_ulrb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot ulrb clustering results and silhouette scores — plot_ulrb","text":"","code":"# \\donttest{ classified_species <- define_rb(nice_tidy) #> Joining with `by = join_by(Sample, Level)`  # Default parameters for a single sample ERR2044669 plot_ulrb(classified_species,           sample_id = \"ERR2044669\",           taxa_col = \"OTU\",           abundance_col = \"Abundance\") #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`). #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`).   # All samples in a dataset plot_ulrb(classified_species,           taxa_col = \"OTU\",           abundance_col = \"Abundance\",           plot_all = TRUE) #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`). #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`).   # All samples with a log scale plot_ulrb(classified_species,           taxa_col = \"OTU\",           abundance_col = \"Abundance\",           plot_all = TRUE,           log_scaled = TRUE) #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`). #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`).  # }"},{"path":"https://pascoalf.github.io/ulrb/reference/plot_ulrb_clustering.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Rank Abundance Curve of classification results — plot_ulrb_clustering","title":"Plot Rank Abundance Curve of classification results — plot_ulrb_clustering","text":"Plots clustering results define_rb().","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/plot_ulrb_clustering.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Rank Abundance Curve of classification results — plot_ulrb_clustering","text":"","code":"plot_ulrb_clustering(   data,   sample_id = NULL,   taxa_col,   plot_all = FALSE,   samples_col = \"Sample\",   classification_col = \"Classification\",   abundance_col = \"Abundance\",   log_scaled = FALSE,   colors = c(\"#009E73\", \"#F0E442\", \"#CC79A7\"),   ... )"},{"path":"https://pascoalf.github.io/ulrb/reference/plot_ulrb_clustering.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Rank Abundance Curve of classification results — plot_ulrb_clustering","text":"data data.frame , least, classification, abundance sample information phylogenetic unit. sample_id string name selected sample. taxa_col string name column phylogenetic units. Usually OTU ASV. plot_all TRUE, make plot samples mean standard deviation. FALSE (default), plot illustrate single sample, specifiy sample_id argument. samples_col name column sample ID's. classification_col string name column classification row. Default value \"Classification\". abundance_col string name column abundance values. Default \"Abundance\". log_scaled TRUE abundance scores shown Log10 scale. Default FALSE. colors vector colors. lenght number classifications. ... arguments.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/plot_ulrb_clustering.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Rank Abundance Curve of classification results — plot_ulrb_clustering","text":"ggplot object clustering results define_rb().","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/plot_ulrb_clustering.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Rank Abundance Curve of classification results — plot_ulrb_clustering","text":"works sanity check results obtained unsupervised learning method used classify species. specially important used automatic number clusters. function works either single sample (specify sample_id argument), can apply centrality metric species across samples (plot_all = TRUE).","code":""},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/reference/plot_ulrb_clustering.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Rank Abundance Curve of classification results — plot_ulrb_clustering","text":"","code":"classified_species <- define_rb(nice_tidy) #> Joining with `by = join_by(Sample, Level)`  # Standard plot for a single sample plot_ulrb_clustering(classified_species,                        sample_id = \"ERR2044669\",                        taxa_col = \"OTU\",                        abundance_col = \"Abundance\") #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`).  # All samples in a dataset plot_ulrb_clustering(classified_species,           taxa_col = \"OTU\",           abundance_col = \"Abundance\",           plot_all = TRUE) #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`).   # All samples with a log scale plot_ulrb_clustering(classified_species,           taxa_col = \"OTU\",           abundance_col = \"Abundance\",           plot_all = TRUE,           log_scaled = TRUE) #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`)."},{"path":"https://pascoalf.github.io/ulrb/reference/plot_ulrb_silhouette.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot silhouette scores from clustering results — plot_ulrb_silhouette","title":"Plot silhouette scores from clustering results — plot_ulrb_silhouette","text":"Plots Silhouette scores clustering results define_rb().","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/plot_ulrb_silhouette.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot silhouette scores from clustering results — plot_ulrb_silhouette","text":"","code":"plot_ulrb_silhouette(   data,   sample_id = NULL,   taxa_col,   samples_col = \"Sample\",   plot_all = FALSE,   classification_col = \"Classification\",   silhouette_score = \"Silhouette_scores\",   colors = c(\"#009E73\", \"#F0E442\", \"#CC79A7\"),   log_scaled = FALSE,   ... )"},{"path":"https://pascoalf.github.io/ulrb/reference/plot_ulrb_silhouette.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot silhouette scores from clustering results — plot_ulrb_silhouette","text":"data ... sample_id string name selected sample. taxa_col string name column phylogenetic units. Usually OTU ASV. samples_col name column sample ID's. plot_all TRUE, make plot samples mean standard deviation. FALSE (default), plot illustrate single sample, specifiy sample_id argument. classification_col string name column classification row. Default value \"Classification\". silhouette_score string column name silhouette score values. Default \"Silhouette_scores\" colors vector colors. lenght number classifications. log_scaled TRUE abundance scores shown Log10 scale. Default FALSE. ... arguments.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/plot_ulrb_silhouette.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot silhouette scores from clustering results — plot_ulrb_silhouette","text":"ggplot object Silhouette plot obtained selected sample.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/plot_ulrb_silhouette.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot silhouette scores from clustering results — plot_ulrb_silhouette","text":"works sanity check results obtained unsupervised learning method used classify species. specially important used automatic number clusters. function works either single sample (specify sample_id argument), can apply centrality metric species across samples (plot_all = TRUE). details Silhouette score, see check_avgSil() cluster::silhouette(). Interpretation Silhouette plot Based chapter 2 \"Finding Groups Data: Introduction Cluster Analysis.\" (Kaufman Rousseeuw, 1991); possible (subjective) interpretation clustering structure based Silhouette plot : 0.71-1.00 (strong structure found); 0.51-0.70 (reasonable structure found); 0.26-0.50 (structure weak artificial); < 0.26 (structure found).","code":""},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/reference/plot_ulrb_silhouette.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot silhouette scores from clustering results — plot_ulrb_silhouette","text":"","code":"classified_species <- define_rb(nice_tidy) #> Joining with `by = join_by(Sample, Level)`  # Standard plot for a single sample plot_ulrb_silhouette(classified_species,                        sample_id = \"ERR2044669\",                        taxa_col = \"OTU\",                        abundance_col = \"Abundance\") #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`).  # All samples in a dataset plot_ulrb_silhouette(classified_species,           taxa_col = \"OTU\",           abundance_col = \"Abundance\",           plot_all = TRUE) #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`).   # All samples with a log scale plot_ulrb_silhouette(classified_species,           taxa_col = \"OTU\",           abundance_col = \"Abundance\",           plot_all = TRUE,           log_scaled = TRUE) #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`)."},{"path":"https://pascoalf.github.io/ulrb/reference/prepare_tidy_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare data in tidy format — prepare_tidy_data","title":"Prepare data in tidy format — prepare_tidy_data","text":"Function transforms common abundance table formats \"long\" format.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/prepare_tidy_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare data in tidy format — prepare_tidy_data","text":"","code":"prepare_tidy_data(data, sample_names, samples_in = \"cols\", ...)"},{"path":"https://pascoalf.github.io/ulrb/reference/prepare_tidy_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare data in tidy format — prepare_tidy_data","text":"data data.frame \"wide\" format, samples either columns rows. data.frame include data besides abundance values per sample, per taxonomic unit. Additional data (e.g. taxonomy details) added afterwards. sample_names vector name samples. samples_in vector specifying location samples. can either \"cols\" (default) samples columns, \"rows\" samples rows. ... additional arguments","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/prepare_tidy_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare data in tidy format — prepare_tidy_data","text":"abundance table long format, compatible dplyr pipes ulrb package functions.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/prepare_tidy_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prepare data in tidy format — prepare_tidy_data","text":"function guarantees abundance table includes one column sample ID's one column abundance. Common species table formats two common formats abundance tables: samples rows phylogenetic units columns; phylogenetic units rows samples columns. However, formats tidy, include several columns variable. \"wide format\" instead \"long format\". function re-organizes samples phylogenetic units single column samples ID's another abundance scores; Extra columns allowed.","code":""},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/reference/prepare_tidy_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare data in tidy format — prepare_tidy_data","text":"","code":"library(dplyr) # sample_names <- c(\"ERR2044662\", \"ERR2044663\", \"ERR2044664\",                    \"ERR2044665\", \"ERR2044666\", \"ERR2044667\",                    \"ERR2044668\", \"ERR2044669\", \"ERR2044670\")  # Example for samples in cols and with additional data available prepare_tidy_data(nice, sample_names = sample_names, samples_in = \"cols\") #> # A tibble: 4,716 × 10 #>    OTU   Domain      Phylum    Class Order Family Genus Species Sample Abundance #>    <chr> <chr>       <chr>     <chr> <chr> <chr>  <chr> <chr>   <chr>      <int> #>  1 OTU_2 sk__Archaea p__Eurya… c__C… NA    NA     NA    NA      ERR20…       165 #>  2 OTU_2 sk__Archaea p__Eurya… c__C… NA    NA     NA    NA      ERR20…       323 #>  3 OTU_2 sk__Archaea p__Eurya… c__C… NA    NA     NA    NA      ERR20…        51 #>  4 OTU_2 sk__Archaea p__Eurya… c__C… NA    NA     NA    NA      ERR20…        70 #>  5 OTU_2 sk__Archaea p__Eurya… c__C… NA    NA     NA    NA      ERR20…       134 #>  6 OTU_2 sk__Archaea p__Eurya… c__C… NA    NA     NA    NA      ERR20…       216 #>  7 OTU_2 sk__Archaea p__Eurya… c__C… NA    NA     NA    NA      ERR20…         0 #>  8 OTU_2 sk__Archaea p__Eurya… c__C… NA    NA     NA    NA      ERR20…        11 #>  9 OTU_2 sk__Archaea p__Eurya… c__C… NA    NA     NA    NA      ERR20…         0 #> 10 OTU_3 sk__Archaea p__Eurya… c__C… o__C… f__    g__   s__Mar… ERR20…         0 #> # ℹ 4,706 more rows  # Example for samples in rows # Select columns with samples from nice nice_rows <- nice %>% select(all_of(sample_names))  # Change columns to rows nice_rows <- nice_rows %>% t() %>% as.data.frame()  # Turn colnames into phylogenetic units ID colnames(nice_rows) <- paste0(\"OTU_\", seq_along(colnames(nice_rows)))  prepare_tidy_data(nice_rows, sample_names = sample_names, samples_in = \"rows\") #> Taxa_id assumes each column is a taxonomic unit. #> # A tibble: 4,716 × 3 #> # Groups:   Sample [9] #>    Sample     Abundance Taxa_id #>    <chr>          <int> <chr>   #>  1 ERR2044662       165 OTU_1   #>  2 ERR2044663       323 OTU_1   #>  3 ERR2044664        51 OTU_1   #>  4 ERR2044665        70 OTU_1   #>  5 ERR2044666       134 OTU_1   #>  6 ERR2044667       216 OTU_1   #>  7 ERR2044668         0 OTU_1   #>  8 ERR2044669        11 OTU_1   #>  9 ERR2044670         0 OTU_1   #> 10 ERR2044662         0 OTU_2   #> # ℹ 4,706 more rows"},{"path":"https://pascoalf.github.io/ulrb/reference/suggest_k.html","id":null,"dir":"Reference","previous_headings":"","what":"Suggest k — suggest_k","title":"Suggest k — suggest_k","text":"Tool help decide many clusters use partition around medoids algorithm.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/suggest_k.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Suggest k — suggest_k","text":"","code":"suggest_k(   data,   range = 3:10,   samples_col = \"Sample\",   abundance_col = \"Abundance\",   index = \"Average Silhouette Score\",   detailed = FALSE,   ... )"},{"path":"https://pascoalf.github.io/ulrb/reference/suggest_k.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Suggest k — suggest_k","text":"data data.frame , least, classification, abundance sample information phylogenetic unit. range range values k test, default 3 10. samples_col String name column sample names. abundance_col string name column abundance values. Default \"Abundance\". index Index used select best k. Can one : \"Average Silhouette Score\", \"Davies-Bouldin\" \"Calinski-Harabasz\". detailed False (default) returns integer best overall k. TRUE, returns list full details. ... Extra arguments.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/suggest_k.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Suggest k — suggest_k","text":"Integer indicating best k selected index. Optionally, can return list details.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/suggest_k.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Suggest k — suggest_k","text":"best k selected sample, based selected index. different k's obtained different samples (probable) calculate mean value k return integer. Alternatively, can return detailed result form list. Note: function used within define_rb(), default parameters, optional automatic selection k. Detailed option detailed = TRUE, output list information help decide k. specifically, list include: data.frame summarizing information index provides interpret value. brief summary indicating number samples dataset range k values used. data.frame best k sample, based index. Automatic k selection detailed = FALSE, function provide single integer best k. default decision based maximum average Silhouette score obtained values k 3 10. better understand average Silhouette score range k's selected, refer Pascoal et al., 2024 (peer-review) vignette(\"explore-classifications\"). Alternatively, function can also provide best k, integer, based another index (Davies-Bouldin Calinski-Harabasz) can compare entire possible k's.","code":""},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/reference/suggest_k.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Suggest k — suggest_k","text":"","code":"# \\donttest{ # Get the best k with default parameters suggest_k(nice_tidy) #> [1] 3   # Get detailed results to decide for yourself suggest_k(nice_tidy, detailed = TRUE, range = 2:7) #> [[1]] #> [1] \"This list contains several details that might help you decide a k parameter.\" #>  #> [[2]] #>                      Score                 Criteria                     Details #> 1     Davies-Bouldin index Minimum value for best k Measures cluster separation #> 2  Calinski-Harabasz index Maximum value for best k Measures cluster definition #> 3 Average Silhouette Score Maximum value for best k    Measures cluster density #>  #> $SamplesSummary #> [1] \"You study has 9 samples. For each one we calculated all indices obtained for each k, from 2 to 7\" #>  #> $DaviesBouldin #> # A tibble: 9 × 3 #>   Sample         CH     k #>   <chr>       <dbl> <int> #> 1 ERR2044662 17589.     7 #> 2 ERR2044663 12741.     7 #> 3 ERR2044664 87610.     7 #> 4 ERR2044665  9486.     6 #> 5 ERR2044666 19652.     7 #> 6 ERR2044667  6504.     7 #> 7 ERR2044669  6616.     7 #> 8 ERR2044668 36144.     7 #> 9 ERR2044670  9480.     7 #>  #> $CalinskiHarabasz #> # A tibble: 9 × 3 #>   Sample         CH     k #>   <chr>       <dbl> <int> #> 1 ERR2044662 17589.     7 #> 2 ERR2044663 12741.     7 #> 3 ERR2044664 87610.     7 #> 4 ERR2044665  9486.     6 #> 5 ERR2044666 19652.     7 #> 6 ERR2044667  6504.     7 #> 7 ERR2044669  6616.     7 #> 8 ERR2044668 36144.     7 #> 9 ERR2044670  9480.     7 #>  #> $averageSilhouette #> # A tibble: 9 × 3 #>   Sample     average_Silhouette     k #>   <chr>                   <dbl> <int> #> 1 ERR2044662              0.977     2 #> 2 ERR2044663              0.978     2 #> 3 ERR2044664              0.984     2 #> 4 ERR2044665              0.979     2 #> 5 ERR2044666              0.983     2 #> 6 ERR2044667              0.972     2 #> 7 ERR2044669              0.976     2 #> 8 ERR2044668              0.979     2 #> 9 ERR2044670              0.932     3 #>   # Get best k, based on Davies-Bouldin index suggest_k(nice_tidy, detailed = FALSE, index = \"Davies-Bouldin\") #> [1] 6 # }"},{"path":"https://pascoalf.github.io/ulrb/reference/ulrb-package.html","id":null,"dir":"Reference","previous_headings":"","what":"ulrb: Unsupervised Learning Based Definition of Microbial Rare Biosphere — ulrb-package","title":"ulrb: Unsupervised Learning Based Definition of Microbial Rare Biosphere — ulrb-package","text":"R package ulrb stands Unsupervised Machine Learning definition   Rare Biosphere. name suggests, applies unsupervised learning principles   define rare biosphere. specifically, partitioning around medoids (k-medoids) algorithm used   divide phylogenetic units (ASVs, OTUs, Species, …) within microbial community   (usually, sample) clusters. clusters ordered based user-defined   classification vector. default, method classifies phylogenetic units one   : “rare”, “undetermined” “abundant”. alternative, provide functions   help user decide number clusters also provide fully automated   option. Besides clustering, functions help evaluate clustering   quality (e.g. silhouette scores). detailed theory behind reasoning definition microbial rare biosphere,   results applications, see paper Pascoal et al., 2023 (preparation).   details R functions used data wrangling please see package documentation.","code":""},{"path":[]},{"path":"https://pascoalf.github.io/ulrb/reference/ulrb-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"ulrb: Unsupervised Learning Based Definition of Microbial Rare Biosphere — ulrb-package","text":"Pascoal, F., Paula, B., Torgo, L., Costa, R., Magalhães, C. (2023) Unsupervised machine learning definition microbial rare biosphere Manuscript preparation.","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/ulrb-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ulrb: Unsupervised Learning Based Definition of Microbial Rare Biosphere — ulrb-package","text":"Francisco Pascoal fpascoal1996@gmail.com, Paula Branco   paobranco@gmail.com, Luis Torgo, Rodrigo Costa rodrigoscosta@tecnico.ulisboa.pt, Catarina Magalhães catarinamagalhaes1972@gmail.com Maintainer:     Francisco Pascoal","code":""},{"path":"https://pascoalf.github.io/ulrb/reference/ulrb-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ulrb: Unsupervised Learning Based Definition of Microbial Rare Biosphere — ulrb-package","text":"","code":"# \\donttest{     library(ulrb)     # nice is an OTU table in wide format     head(nice) #>   ERR2044662 ERR2044663 ERR2044664 ERR2044665 ERR2044666 ERR2044667 ERR2044668 #> 1        165        323         51         70        134        216          0 #> 2          0          0          1          0          0          1          0 #> 3          0          0          1          2          2          6          0 #> 4        541       1018        351        115        241       1633        177 #> 5          8          5         41         15         14        146          0 #> 6         15         31        590        133        174       1814         12 #>   ERR2044669 ERR2044670   OTU      Domain            Phylum #> 1         11          0 OTU_2 sk__Archaea  p__Euryarchaeota #> 2          0          0 OTU_3 sk__Archaea  p__Euryarchaeota #> 3          0          0 OTU_4 sk__Archaea  p__Euryarchaeota #> 4       1371          7 OTU_5 sk__Archaea  p__Euryarchaeota #> 5         14          0 OTU_6 sk__Archaea p__Thaumarchaeota #> 6        173          2 OTU_7 sk__Archaea p__Thaumarchaeota #>                       Class                       Order Family #> 1 c__Candidatus_Poseidoniia                        <NA>   <NA> #> 2 c__Candidatus_Poseidoniia o__Candidatus_Poseidoniales    f__ #> 3           c__Halobacteria          o__Halobacteriales   <NA> #> 4         c__Thermoplasmata                        <NA>   <NA> #> 5                      <NA>                        <NA>   <NA> #> 6                       c__                         o__    f__ #>                            Genus                                        Species #> 1                           <NA>                                           <NA> #> 2                            g__ s__Marine_group_II_euryarchaeote_REDSEA-S03_B6 #> 3                           <NA>                                           <NA> #> 4                           <NA>                                           <NA> #> 5                           <NA>                                           <NA> #> 6 g__Candidatus_Nitrosopelagicus                                           <NA>      # first, we tidy the \"nice\" OTU table     sample_names <- c(\"ERR2044662\", \"ERR2044663\", \"ERR2044664\",                       \"ERR2044665\", \"ERR2044666\", \"ERR2044667\",                       \"ERR2044668\", \"ERR2044669\", \"ERR2044670\")      # If data is in wide format, with samples in cols     nice_tidy <- prepare_tidy_data(nice,                                    sample_names = sample_names,                                    samples_in = \"cols\")      # second, we apply ulrb algorithm in automatic setting     nice_classification_results <- define_rb(nice_tidy) #> Joining with `by = join_by(Sample, Level)`      # third, we plot microbial community and the quality of k-medoids clustering     plot_ulrb(nice_classification_results, taxa_col = \"OTU\", plot_all = TRUE) #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`). #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`).       # In case you want to inspect the result of a particular sample, do:     plot_ulrb(nice_classification_results, taxa_col = \"OTU\", sample_id = \"ERR2044662\") #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`). #> Warning: Removed 197 rows containing missing values or values outside the scale range #> (`geom_segment()`).          # }"}]
